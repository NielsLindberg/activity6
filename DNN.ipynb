{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Chest Pain</th>\n",
       "      <th>Genereal level of tiredness</th>\n",
       "      <th>Pulse, resting</th>\n",
       "      <th>Blood Type</th>\n",
       "      <th>Heart disease mom/dad</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>Use of contact lenses</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>H�matokritv�rdi</th>\n",
       "      <th>EKG</th>\n",
       "      <th>Go to doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>Periodic</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0 pos</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>121</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>38</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>6</td>\n",
       "      <td>Often</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>0 pos</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>118</td>\n",
       "      <td>Y</td>\n",
       "      <td>Type 1</td>\n",
       "      <td>39</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>OBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>Periodic</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>B pos</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>154</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>41</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>Often</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>B pos</td>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>40</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>B pos</td>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>124</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>42</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender  Age Chest Pain  Genereal level of tiredness  Pulse, resting  \\\n",
       "0      M    4   Periodic                            4              59   \n",
       "1      M    6      Often                            8              80   \n",
       "2      F   15   Periodic                            0              67   \n",
       "3      M   15      Often                           10              69   \n",
       "4      F   17       None                            1              72   \n",
       "\n",
       "  Blood Type Heart disease mom/dad  Smoking  Cholesterol  Alcohol  BMI  \\\n",
       "0      0 pos                     N        0            1        6   22   \n",
       "1      0 pos                     N        0            6       10   35   \n",
       "2      B pos                     Y        4            1        0   22   \n",
       "3      B pos                     Y        6            1        0   22   \n",
       "4      B pos                     N        7            1        6   22   \n",
       "\n",
       "   Fitness Use of contact lenses Diabetes  H�matokritv�rdi           EKG  \\\n",
       "0      121                     N  Healthy               38  Anormalities   \n",
       "1      118                     Y   Type 1               39  Anormalities   \n",
       "2      154                     N  Healthy               41        Normal   \n",
       "3      150                     N  Healthy               40  Anormalities   \n",
       "4      124                     N  Healthy               42  Anormalities   \n",
       "\n",
       "  Go to doctor  \n",
       "0           NO  \n",
       "1          OBS  \n",
       "2           NO  \n",
       "3           NO  \n",
       "4           NO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Go to doctor_YES  Go to doctor_OBS  Go to doctor_NO\n",
      "0                 0                 0                1\n",
      "1                 0                 1                0\n",
      "2                 0                 0                1\n",
      "3                 0                 0                1\n",
      "4                 0                 0                1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "category_fields = ['Gender', 'Chest Pain', 'Blood Type', 'Heart disease mom/dad', 'Use of contact lenses', \n",
    "                   'Diabetes', 'EKG', 'Go to doctor']\n",
    "\n",
    "for each in category_fields:\n",
    "    dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    \n",
    "df = df.drop(category_fields, axis=1)\n",
    "\n",
    "pd_y = df[['Go to doctor_YES', 'Go to doctor_OBS', 'Go to doctor_NO']]\n",
    "pd_x = df.drop(['Go to doctor_YES', 'Go to doctor_OBS', 'Go to doctor_NO'], axis=1)\n",
    "print(pd_y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pd_x, pd_y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0)\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_test, y_test, \n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state=0)\n",
    "\n",
    "def chunk(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "train_xb, train_yb = list(chunk(X_train, 8)), list(chunk(y_train, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def hidden_layer(inputs, nodes, keep_rate, norm, training):\n",
    "    outputs = tf.layers.dense(inputs, nodes, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    if norm == 1:\n",
    "        outputs = tf.layers.batch_normalization(outputs, training=training)\n",
    "    outputs = tf.layers.dropout(outputs, 1-keep_rate, training=training)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_logits(net):\n",
    "    norm_input = tf.layers.batch_normalization(net.inputs_, training=net.training_)\n",
    "    hl = hidden_layer(norm_input, net.nodes, net.krate, 1, net.training_)\n",
    "    hl = hidden_layer(hl, net.nodes, net.krate, 1, net.training_)\n",
    "    logits = hidden_layer(hl, 3, net.krate, 1, net.training_)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_cost(logits, targets):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets),name='cross_entropy')\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_softmax(logits):\n",
    "    return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_cross_entropy(cost):\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.summary.scalar('cross_entropy', cost)\n",
    "        return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def set_hypertune_param(cost):\n",
    "    with tf.name_scope('hypertune'):\n",
    "        hypertune = tf.summary.scalar('training/hptuning/metric', cost)\n",
    "        return hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_optimizer(cost, lr):\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, targets):\n",
    "    predictions_pd = pd.DataFrame(pred[:,:], columns=['YES', 'OBS', 'NO'])\n",
    "    targets_pd = pd.DataFrame(targets[:,:], columns=['YES', 'OBS', 'NO'])\n",
    "    predictions_pd['pred_bins'] = predictions_pd.idxmax(axis=1)\n",
    "    targets_pd['targ_bins'] = targets_pd.idxmax(axis=1)\n",
    "    test_pd = pd.concat([predictions_pd, targets_pd], axis=1)\n",
    "    test_pd['tp'] = 0\n",
    "    test_pd['fp'] = 0\n",
    "    test_pd['fn'] = 0\n",
    "\n",
    "    for each in ['YES', 'OBS', 'NO']:\n",
    "        test_pd['tp_' + each] = test_pd.apply(\n",
    "            lambda x: 1 if x['pred_bins'] == each and x['targ_bins'] == each else 0, axis=1).astype(float)\n",
    "        test_pd['tp'] += test_pd['tp_' + each]\n",
    "    \n",
    "        test_pd['fp_' + each] = test_pd.apply(\n",
    "            lambda x: 1 if x['pred_bins'] == each and x['targ_bins'] != each else 0, axis=1).astype(float)\n",
    "        test_pd['fp'] += test_pd['fp_' + each]\n",
    "\n",
    "        test_pd['fn_' + each] = test_pd.apply(\n",
    "            lambda x: 1 if x['pred_bins'] != each and x['targ_bins'] == each else 0, axis=1).astype(float)\n",
    "        test_pd['fn'] += test_pd['fn_' + each]\n",
    "    \n",
    "    print(test_pd.head())\n",
    "    return test_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class FFDNN:\n",
    "    def __init__(self):\n",
    "        print('MODEL INIT')\n",
    "        tf.reset_default_graph()\n",
    "        self.epochs = 1000\n",
    "        self.layers = 2\n",
    "        self.nodes = 200\n",
    "        self.krate = 0.5\n",
    "        self.batchtrain = False\n",
    "        self.input_shape = [None, train_xb[0].as_matrix().shape[1]]\n",
    "        self.output_shape = [None, train_yb[0].as_matrix().shape[1]]\n",
    "        self.inputs_ = tf.placeholder(tf.float32, shape=self.input_shape, name='inputs')\n",
    "        self.targets_ = tf.placeholder(tf.float32, shape=self.output_shape, name='targets')\n",
    "        self.train_learning_rate = 0.001\n",
    "        self.lr_ = tf.placeholder(tf.float32, shape=[], name='lr')\n",
    "        self.training_ = tf.placeholder(tf.bool, shape=[], name='training')\n",
    "        self.logits = get_logits(self)\n",
    "        self.softmax = get_softmax(self.logits)\n",
    "        self.cost = get_cost(self.logits, self.targets_)\n",
    "        self.cross_entropy = write_cross_entropy(self.cost)\n",
    "        self.hypertune = set_hypertune_param(self.cost)\n",
    "        self.optimizer = get_optimizer(self.cost, self.lr_)\n",
    "        self.saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(net):\n",
    "    print('TRAIN')\n",
    "    with tf.Session() as sess:\n",
    "        ##sess.run(tf.global_variables_initializer())\n",
    "        ckpt = './activity6.ckpt'\n",
    "        net.saver.restore(sess, ckpt)\n",
    "        train_writer = tf.summary.FileWriter('logs/train', sess.graph)\n",
    "        eval_writer = tf.summary.FileWriter('logs/eval', sess.graph)\n",
    "        \n",
    "        iteration = 0\n",
    "        for e in range(net.epochs):\n",
    "            \n",
    "            if net.batchtrain == True:\n",
    "                for b_idx, b in enumerate(train_xb,0):\n",
    "                    iteration += 1\n",
    "                    x, y = train_xb[b_idx].as_matrix(), train_yb[b_idx].as_matrix()\n",
    "                    train_merged = tf.summary.merge([net.cross_entropy])\n",
    "\n",
    "                    # Train\n",
    "                    feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: True}\n",
    "                    summary_train, _ = sess.run([train_merged, net.optimizer], feed_dict=feed)\n",
    "                    train_writer.add_summary(summary_train, iteration)\n",
    "            else:\n",
    "                iteration += 1\n",
    "                x, y = X_train.as_matrix(), y_train.as_matrix()\n",
    "                train_merged = tf.summary.merge([net.cross_entropy])\n",
    "\n",
    "                # Train\n",
    "                feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: True}\n",
    "                summary_train, _ = sess.run([train_merged, net.optimizer], feed_dict=feed)\n",
    "                train_writer.add_summary(summary_train, iteration)\n",
    "                \n",
    "            x, y = X_eval.as_matrix(), y_eval.as_matrix()\n",
    "\n",
    "            feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: False}\n",
    "            summary_train_eval, cost = sess.run([train_merged, net.cost], feed_dict=feed)\n",
    "            \n",
    "            eval_writer.add_summary(summary_train_eval, iteration)\n",
    "            \n",
    "            print('Epoch ' + str(e) + ': Eval Loss = ' + str(cost))\n",
    "\n",
    "        train_writer.close()\n",
    "        eval_writer.close()\n",
    "        net.saver.save(sess, './activity6.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test(net):\n",
    "    print('TEST')\n",
    "    with tf.Session() as sess:\n",
    "        ckpt = './activity6.ckpt'\n",
    "        net.saver.restore(sess, ckpt)\n",
    "            \n",
    "        x, y = X_test.as_matrix(), y_test.as_matrix()\n",
    "\n",
    "        feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: False}\n",
    "        pred = sess.run(net.softmax, feed_dict=feed)\n",
    "    \n",
    "    details_test = calculate_metrics(pred, y)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        net.saver.restore(sess, ckpt)\n",
    "        \n",
    "        x_all = pd.concat([X_train, X_test, X_eval], axis=0)\n",
    "        y_all = pd.concat([y_train, y_test, y_eval], axis=0)\n",
    "        x, y = x_all.as_matrix(), y_all.as_matrix()\n",
    "\n",
    "        feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: False}\n",
    "        pred = sess.run(net.softmax, feed_dict=feed)\n",
    "    \n",
    "    details_all = calculate_metrics(pred, y)\n",
    "    return details_test, details_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INIT\n",
      "TRAIN\n",
      "INFO:tensorflow:Restoring parameters from ./activity6.ckpt\n",
      "Epoch 0: Eval Loss = 0.69617987\n",
      "Epoch 1: Eval Loss = 0.6961403\n",
      "Epoch 2: Eval Loss = 0.69612473\n",
      "Epoch 3: Eval Loss = 0.6960823\n",
      "Epoch 4: Eval Loss = 0.6960686\n",
      "Epoch 5: Eval Loss = 0.6960243\n",
      "Epoch 6: Eval Loss = 0.6959478\n",
      "Epoch 7: Eval Loss = 0.69588643\n",
      "Epoch 8: Eval Loss = 0.69582367\n",
      "Epoch 9: Eval Loss = 0.6957766\n",
      "Epoch 10: Eval Loss = 0.6956907\n",
      "Epoch 11: Eval Loss = 0.69562316\n",
      "Epoch 12: Eval Loss = 0.69557226\n",
      "Epoch 13: Eval Loss = 0.6955138\n",
      "Epoch 14: Eval Loss = 0.69543296\n",
      "Epoch 15: Eval Loss = 0.69539446\n",
      "Epoch 16: Eval Loss = 0.69533956\n",
      "Epoch 17: Eval Loss = 0.6952959\n",
      "Epoch 18: Eval Loss = 0.69526845\n",
      "Epoch 19: Eval Loss = 0.69521856\n",
      "Epoch 20: Eval Loss = 0.69521433\n",
      "Epoch 21: Eval Loss = 0.69520354\n",
      "Epoch 22: Eval Loss = 0.69516283\n",
      "Epoch 23: Eval Loss = 0.6951327\n",
      "Epoch 24: Eval Loss = 0.6951126\n",
      "Epoch 25: Eval Loss = 0.69509315\n",
      "Epoch 26: Eval Loss = 0.6950402\n",
      "Epoch 27: Eval Loss = 0.69501436\n",
      "Epoch 28: Eval Loss = 0.6949668\n",
      "Epoch 29: Eval Loss = 0.6949137\n",
      "Epoch 30: Eval Loss = 0.69483757\n",
      "Epoch 31: Eval Loss = 0.6947932\n",
      "Epoch 32: Eval Loss = 0.6947554\n",
      "Epoch 33: Eval Loss = 0.694742\n",
      "Epoch 34: Eval Loss = 0.69470125\n",
      "Epoch 35: Eval Loss = 0.6946277\n",
      "Epoch 36: Eval Loss = 0.6945651\n",
      "Epoch 37: Eval Loss = 0.694505\n",
      "Epoch 38: Eval Loss = 0.69445467\n",
      "Epoch 39: Eval Loss = 0.694409\n",
      "Epoch 40: Eval Loss = 0.69437987\n",
      "Epoch 41: Eval Loss = 0.69431704\n",
      "Epoch 42: Eval Loss = 0.6942635\n",
      "Epoch 43: Eval Loss = 0.69421333\n",
      "Epoch 44: Eval Loss = 0.69413096\n",
      "Epoch 45: Eval Loss = 0.6940455\n",
      "Epoch 46: Eval Loss = 0.69397986\n",
      "Epoch 47: Eval Loss = 0.6939118\n",
      "Epoch 48: Eval Loss = 0.693856\n",
      "Epoch 49: Eval Loss = 0.6937998\n",
      "Epoch 50: Eval Loss = 0.69371176\n",
      "Epoch 51: Eval Loss = 0.69363904\n",
      "Epoch 52: Eval Loss = 0.69352525\n",
      "Epoch 53: Eval Loss = 0.69344795\n",
      "Epoch 54: Eval Loss = 0.6933507\n",
      "Epoch 55: Eval Loss = 0.693277\n",
      "Epoch 56: Eval Loss = 0.69319254\n",
      "Epoch 57: Eval Loss = 0.6930713\n",
      "Epoch 58: Eval Loss = 0.6930059\n",
      "Epoch 59: Eval Loss = 0.6929447\n",
      "Epoch 60: Eval Loss = 0.69287765\n",
      "Epoch 61: Eval Loss = 0.6928333\n",
      "Epoch 62: Eval Loss = 0.6927345\n",
      "Epoch 63: Eval Loss = 0.69266534\n",
      "Epoch 64: Eval Loss = 0.6925894\n",
      "Epoch 65: Eval Loss = 0.6924975\n",
      "Epoch 66: Eval Loss = 0.6924676\n",
      "Epoch 67: Eval Loss = 0.6924246\n",
      "Epoch 68: Eval Loss = 0.6923961\n",
      "Epoch 69: Eval Loss = 0.6923867\n",
      "Epoch 70: Eval Loss = 0.69235986\n",
      "Epoch 71: Eval Loss = 0.69235754\n",
      "Epoch 72: Eval Loss = 0.69234717\n",
      "Epoch 73: Eval Loss = 0.6923387\n",
      "Epoch 74: Eval Loss = 0.69234467\n",
      "Epoch 75: Eval Loss = 0.69232255\n",
      "Epoch 76: Eval Loss = 0.6923254\n",
      "Epoch 77: Eval Loss = 0.69231546\n",
      "Epoch 78: Eval Loss = 0.692324\n",
      "Epoch 79: Eval Loss = 0.69231474\n",
      "Epoch 80: Eval Loss = 0.69226736\n",
      "Epoch 81: Eval Loss = 0.6922552\n",
      "Epoch 82: Eval Loss = 0.6922345\n",
      "Epoch 83: Eval Loss = 0.69222116\n",
      "Epoch 84: Eval Loss = 0.6921975\n",
      "Epoch 85: Eval Loss = 0.692183\n",
      "Epoch 86: Eval Loss = 0.6921153\n",
      "Epoch 87: Eval Loss = 0.6920809\n",
      "Epoch 88: Eval Loss = 0.69202065\n",
      "Epoch 89: Eval Loss = 0.6919722\n",
      "Epoch 90: Eval Loss = 0.6919502\n",
      "Epoch 91: Eval Loss = 0.69192594\n",
      "Epoch 92: Eval Loss = 0.6918779\n",
      "Epoch 93: Eval Loss = 0.6918205\n",
      "Epoch 94: Eval Loss = 0.69177455\n",
      "Epoch 95: Eval Loss = 0.69170785\n",
      "Epoch 96: Eval Loss = 0.6916313\n",
      "Epoch 97: Eval Loss = 0.69155663\n",
      "Epoch 98: Eval Loss = 0.69149417\n",
      "Epoch 99: Eval Loss = 0.6914629\n",
      "Epoch 100: Eval Loss = 0.6914097\n",
      "Epoch 101: Eval Loss = 0.69132364\n",
      "Epoch 102: Eval Loss = 0.6912804\n",
      "Epoch 103: Eval Loss = 0.69123954\n",
      "Epoch 104: Eval Loss = 0.69117045\n",
      "Epoch 105: Eval Loss = 0.6911202\n",
      "Epoch 106: Eval Loss = 0.6910691\n",
      "Epoch 107: Eval Loss = 0.6909922\n",
      "Epoch 108: Eval Loss = 0.6909051\n",
      "Epoch 109: Eval Loss = 0.69084585\n",
      "Epoch 110: Eval Loss = 0.69074583\n",
      "Epoch 111: Eval Loss = 0.69070506\n",
      "Epoch 112: Eval Loss = 0.69063973\n",
      "Epoch 113: Eval Loss = 0.69057566\n",
      "Epoch 114: Eval Loss = 0.6905112\n",
      "Epoch 115: Eval Loss = 0.6904504\n",
      "Epoch 116: Eval Loss = 0.69039696\n",
      "Epoch 117: Eval Loss = 0.6903646\n",
      "Epoch 118: Eval Loss = 0.69034266\n",
      "Epoch 119: Eval Loss = 0.690319\n",
      "Epoch 120: Eval Loss = 0.6902896\n",
      "Epoch 121: Eval Loss = 0.69028366\n",
      "Epoch 122: Eval Loss = 0.6902705\n",
      "Epoch 123: Eval Loss = 0.69025636\n",
      "Epoch 124: Eval Loss = 0.6902513\n",
      "Epoch 125: Eval Loss = 0.6902177\n",
      "Epoch 126: Eval Loss = 0.6901783\n",
      "Epoch 127: Eval Loss = 0.6901321\n",
      "Epoch 128: Eval Loss = 0.69008154\n",
      "Epoch 129: Eval Loss = 0.69003123\n",
      "Epoch 130: Eval Loss = 0.69001746\n",
      "Epoch 131: Eval Loss = 0.69003505\n",
      "Epoch 132: Eval Loss = 0.6900243\n",
      "Epoch 133: Eval Loss = 0.6899951\n",
      "Epoch 134: Eval Loss = 0.6899506\n",
      "Epoch 135: Eval Loss = 0.68992025\n",
      "Epoch 136: Eval Loss = 0.68989694\n",
      "Epoch 137: Eval Loss = 0.6898889\n",
      "Epoch 138: Eval Loss = 0.6898491\n",
      "Epoch 139: Eval Loss = 0.6898236\n",
      "Epoch 140: Eval Loss = 0.68979925\n",
      "Epoch 141: Eval Loss = 0.68978256\n",
      "Epoch 142: Eval Loss = 0.68974555\n",
      "Epoch 143: Eval Loss = 0.68972826\n",
      "Epoch 144: Eval Loss = 0.6896894\n",
      "Epoch 145: Eval Loss = 0.6896284\n",
      "Epoch 146: Eval Loss = 0.6895693\n",
      "Epoch 147: Eval Loss = 0.6895166\n",
      "Epoch 148: Eval Loss = 0.689466\n",
      "Epoch 149: Eval Loss = 0.6894226\n",
      "Epoch 150: Eval Loss = 0.68937784\n",
      "Epoch 151: Eval Loss = 0.6893274\n",
      "Epoch 152: Eval Loss = 0.6892791\n",
      "Epoch 153: Eval Loss = 0.68920785\n",
      "Epoch 154: Eval Loss = 0.68912363\n",
      "Epoch 155: Eval Loss = 0.68905395\n",
      "Epoch 156: Eval Loss = 0.6889664\n",
      "Epoch 157: Eval Loss = 0.68885744\n",
      "Epoch 158: Eval Loss = 0.68878037\n",
      "Epoch 159: Eval Loss = 0.6886829\n",
      "Epoch 160: Eval Loss = 0.6885965\n",
      "Epoch 161: Eval Loss = 0.688488\n",
      "Epoch 162: Eval Loss = 0.6883807\n",
      "Epoch 163: Eval Loss = 0.68829787\n",
      "Epoch 164: Eval Loss = 0.68821764\n",
      "Epoch 165: Eval Loss = 0.68817633\n",
      "Epoch 166: Eval Loss = 0.6881303\n",
      "Epoch 167: Eval Loss = 0.6880911\n",
      "Epoch 168: Eval Loss = 0.68806535\n",
      "Epoch 169: Eval Loss = 0.6880239\n",
      "Epoch 170: Eval Loss = 0.6880006\n",
      "Epoch 171: Eval Loss = 0.6879665\n",
      "Epoch 172: Eval Loss = 0.6879131\n",
      "Epoch 173: Eval Loss = 0.6878676\n",
      "Epoch 174: Eval Loss = 0.68780345\n",
      "Epoch 175: Eval Loss = 0.6877744\n",
      "Epoch 176: Eval Loss = 0.68775207\n",
      "Epoch 177: Eval Loss = 0.6877409\n",
      "Epoch 178: Eval Loss = 0.68773156\n",
      "Epoch 179: Eval Loss = 0.68768686\n",
      "Epoch 180: Eval Loss = 0.68762606\n",
      "Epoch 181: Eval Loss = 0.68756735\n",
      "Epoch 182: Eval Loss = 0.6874983\n",
      "Epoch 183: Eval Loss = 0.6874654\n",
      "Epoch 184: Eval Loss = 0.687442\n",
      "Epoch 185: Eval Loss = 0.6874239\n",
      "Epoch 186: Eval Loss = 0.687398\n",
      "Epoch 187: Eval Loss = 0.6874111\n",
      "Epoch 188: Eval Loss = 0.6874047\n",
      "Epoch 189: Eval Loss = 0.68738455\n",
      "Epoch 190: Eval Loss = 0.6873547\n",
      "Epoch 191: Eval Loss = 0.6873166\n",
      "Epoch 192: Eval Loss = 0.6872641\n",
      "Epoch 193: Eval Loss = 0.68720084\n",
      "Epoch 194: Eval Loss = 0.687165\n",
      "Epoch 195: Eval Loss = 0.6871408\n",
      "Epoch 196: Eval Loss = 0.6871079\n",
      "Epoch 197: Eval Loss = 0.68705577\n",
      "Epoch 198: Eval Loss = 0.68701774\n",
      "Epoch 199: Eval Loss = 0.6869741\n",
      "Epoch 200: Eval Loss = 0.6869355\n",
      "Epoch 201: Eval Loss = 0.68692344\n",
      "Epoch 202: Eval Loss = 0.6868896\n",
      "Epoch 203: Eval Loss = 0.6868666\n",
      "Epoch 204: Eval Loss = 0.68686277\n",
      "Epoch 205: Eval Loss = 0.68680984\n",
      "Epoch 206: Eval Loss = 0.6867831\n",
      "Epoch 207: Eval Loss = 0.68675494\n",
      "Epoch 208: Eval Loss = 0.686726\n",
      "Epoch 209: Eval Loss = 0.686697\n",
      "Epoch 210: Eval Loss = 0.6866568\n",
      "Epoch 211: Eval Loss = 0.68664217\n",
      "Epoch 212: Eval Loss = 0.68661326\n",
      "Epoch 213: Eval Loss = 0.68656266\n",
      "Epoch 214: Eval Loss = 0.68647414\n",
      "Epoch 215: Eval Loss = 0.68643785\n",
      "Epoch 216: Eval Loss = 0.6863924\n",
      "Epoch 217: Eval Loss = 0.68635774\n",
      "Epoch 218: Eval Loss = 0.68631804\n",
      "Epoch 219: Eval Loss = 0.6862992\n",
      "Epoch 220: Eval Loss = 0.68625677\n",
      "Epoch 221: Eval Loss = 0.6861976\n",
      "Epoch 222: Eval Loss = 0.68612856\n",
      "Epoch 223: Eval Loss = 0.68603736\n",
      "Epoch 224: Eval Loss = 0.68600047\n",
      "Epoch 225: Eval Loss = 0.6859565\n",
      "Epoch 226: Eval Loss = 0.68590283\n",
      "Epoch 227: Eval Loss = 0.68589365\n",
      "Epoch 228: Eval Loss = 0.68584424\n",
      "Epoch 229: Eval Loss = 0.68582094\n",
      "Epoch 230: Eval Loss = 0.68578047\n",
      "Epoch 231: Eval Loss = 0.6857627\n",
      "Epoch 232: Eval Loss = 0.68575394\n",
      "Epoch 233: Eval Loss = 0.68572533\n",
      "Epoch 234: Eval Loss = 0.68571085\n",
      "Epoch 235: Eval Loss = 0.68569785\n",
      "Epoch 236: Eval Loss = 0.6856875\n",
      "Epoch 237: Eval Loss = 0.6856738\n",
      "Epoch 238: Eval Loss = 0.6856605\n",
      "Epoch 239: Eval Loss = 0.68565977\n",
      "Epoch 240: Eval Loss = 0.6856726\n",
      "Epoch 241: Eval Loss = 0.68567884\n",
      "Epoch 242: Eval Loss = 0.68571174\n",
      "Epoch 243: Eval Loss = 0.68571526\n",
      "Epoch 244: Eval Loss = 0.68573195\n",
      "Epoch 245: Eval Loss = 0.6857087\n",
      "Epoch 246: Eval Loss = 0.6856763\n",
      "Epoch 247: Eval Loss = 0.6856459\n",
      "Epoch 248: Eval Loss = 0.6856281\n",
      "Epoch 249: Eval Loss = 0.6856096\n",
      "Epoch 250: Eval Loss = 0.6856076\n",
      "Epoch 251: Eval Loss = 0.6855961\n",
      "Epoch 252: Eval Loss = 0.68559575\n",
      "Epoch 253: Eval Loss = 0.68558174\n",
      "Epoch 254: Eval Loss = 0.68555176\n",
      "Epoch 255: Eval Loss = 0.6855256\n",
      "Epoch 256: Eval Loss = 0.68551356\n",
      "Epoch 257: Eval Loss = 0.6854828\n",
      "Epoch 258: Eval Loss = 0.6854529\n",
      "Epoch 259: Eval Loss = 0.6854164\n",
      "Epoch 260: Eval Loss = 0.6853663\n",
      "Epoch 261: Eval Loss = 0.6853544\n",
      "Epoch 262: Eval Loss = 0.68534064\n",
      "Epoch 263: Eval Loss = 0.6853161\n",
      "Epoch 264: Eval Loss = 0.68527657\n",
      "Epoch 265: Eval Loss = 0.6852807\n",
      "Epoch 266: Eval Loss = 0.6852662\n",
      "Epoch 267: Eval Loss = 0.68528104\n",
      "Epoch 268: Eval Loss = 0.68530434\n",
      "Epoch 269: Eval Loss = 0.6853253\n",
      "Epoch 270: Eval Loss = 0.68531364\n",
      "Epoch 271: Eval Loss = 0.68535686\n",
      "Epoch 272: Eval Loss = 0.68538755\n",
      "Epoch 273: Eval Loss = 0.6854112\n",
      "Epoch 274: Eval Loss = 0.6854186\n",
      "Epoch 275: Eval Loss = 0.6854447\n",
      "Epoch 276: Eval Loss = 0.6854338\n",
      "Epoch 277: Eval Loss = 0.6854029\n",
      "Epoch 278: Eval Loss = 0.6853772\n",
      "Epoch 279: Eval Loss = 0.6853684\n",
      "Epoch 280: Eval Loss = 0.6853782\n",
      "Epoch 281: Eval Loss = 0.6853836\n",
      "Epoch 282: Eval Loss = 0.6853654\n",
      "Epoch 283: Eval Loss = 0.6853328\n",
      "Epoch 284: Eval Loss = 0.6852708\n",
      "Epoch 285: Eval Loss = 0.68516403\n",
      "Epoch 286: Eval Loss = 0.6851004\n",
      "Epoch 287: Eval Loss = 0.6850412\n",
      "Epoch 288: Eval Loss = 0.6849955\n",
      "Epoch 289: Eval Loss = 0.6849545\n",
      "Epoch 290: Eval Loss = 0.68496656\n",
      "Epoch 291: Eval Loss = 0.6849426\n",
      "Epoch 292: Eval Loss = 0.68490416\n",
      "Epoch 293: Eval Loss = 0.68487793\n",
      "Epoch 294: Eval Loss = 0.68482965\n",
      "Epoch 295: Eval Loss = 0.68474925\n",
      "Epoch 296: Eval Loss = 0.68470144\n",
      "Epoch 297: Eval Loss = 0.68466246\n",
      "Epoch 298: Eval Loss = 0.68462867\n",
      "Epoch 299: Eval Loss = 0.68460566\n",
      "Epoch 300: Eval Loss = 0.68459094\n",
      "Epoch 301: Eval Loss = 0.68456084\n",
      "Epoch 302: Eval Loss = 0.68450797\n",
      "Epoch 303: Eval Loss = 0.68445414\n",
      "Epoch 304: Eval Loss = 0.68439966\n",
      "Epoch 305: Eval Loss = 0.6843487\n",
      "Epoch 306: Eval Loss = 0.68431455\n",
      "Epoch 307: Eval Loss = 0.6842675\n",
      "Epoch 308: Eval Loss = 0.68422896\n",
      "Epoch 309: Eval Loss = 0.68418115\n",
      "Epoch 310: Eval Loss = 0.6841233\n",
      "Epoch 311: Eval Loss = 0.6840442\n",
      "Epoch 312: Eval Loss = 0.68394136\n",
      "Epoch 313: Eval Loss = 0.68385786\n",
      "Epoch 314: Eval Loss = 0.68374753\n",
      "Epoch 315: Eval Loss = 0.6836754\n",
      "Epoch 316: Eval Loss = 0.6836354\n",
      "Epoch 317: Eval Loss = 0.68359977\n",
      "Epoch 318: Eval Loss = 0.6835744\n",
      "Epoch 319: Eval Loss = 0.68354917\n",
      "Epoch 320: Eval Loss = 0.68353796\n",
      "Epoch 321: Eval Loss = 0.68350655\n",
      "Epoch 322: Eval Loss = 0.68353254\n",
      "Epoch 323: Eval Loss = 0.68356633\n",
      "Epoch 324: Eval Loss = 0.6836142\n",
      "Epoch 325: Eval Loss = 0.6836562\n",
      "Epoch 326: Eval Loss = 0.68368334\n",
      "Epoch 327: Eval Loss = 0.6837128\n",
      "Epoch 328: Eval Loss = 0.68374217\n",
      "Epoch 329: Eval Loss = 0.6837667\n",
      "Epoch 330: Eval Loss = 0.68376714\n",
      "Epoch 331: Eval Loss = 0.68376815\n",
      "Epoch 332: Eval Loss = 0.68378806\n",
      "Epoch 333: Eval Loss = 0.6837679\n",
      "Epoch 334: Eval Loss = 0.6837284\n",
      "Epoch 335: Eval Loss = 0.683693\n",
      "Epoch 336: Eval Loss = 0.6836785\n",
      "Epoch 337: Eval Loss = 0.6836528\n",
      "Epoch 338: Eval Loss = 0.6835818\n",
      "Epoch 339: Eval Loss = 0.6835028\n",
      "Epoch 340: Eval Loss = 0.6834227\n",
      "Epoch 341: Eval Loss = 0.68332916\n",
      "Epoch 342: Eval Loss = 0.68325615\n",
      "Epoch 343: Eval Loss = 0.6832011\n",
      "Epoch 344: Eval Loss = 0.68317115\n",
      "Epoch 345: Eval Loss = 0.6831211\n",
      "Epoch 346: Eval Loss = 0.68305343\n",
      "Epoch 347: Eval Loss = 0.6830149\n",
      "Epoch 348: Eval Loss = 0.68297255\n",
      "Epoch 349: Eval Loss = 0.68294585\n",
      "Epoch 350: Eval Loss = 0.6829276\n",
      "Epoch 351: Eval Loss = 0.68293\n",
      "Epoch 352: Eval Loss = 0.6829189\n",
      "Epoch 353: Eval Loss = 0.6828941\n",
      "Epoch 354: Eval Loss = 0.6828618\n",
      "Epoch 355: Eval Loss = 0.6828559\n",
      "Epoch 356: Eval Loss = 0.68283373\n",
      "Epoch 357: Eval Loss = 0.68280655\n",
      "Epoch 358: Eval Loss = 0.68274117\n",
      "Epoch 359: Eval Loss = 0.6826807\n",
      "Epoch 360: Eval Loss = 0.68263334\n",
      "Epoch 361: Eval Loss = 0.6825722\n",
      "Epoch 362: Eval Loss = 0.68257606\n",
      "Epoch 363: Eval Loss = 0.68258864\n",
      "Epoch 364: Eval Loss = 0.6826202\n",
      "Epoch 365: Eval Loss = 0.6826398\n",
      "Epoch 366: Eval Loss = 0.68266326\n",
      "Epoch 367: Eval Loss = 0.68263596\n",
      "Epoch 368: Eval Loss = 0.682624\n",
      "Epoch 369: Eval Loss = 0.6826221\n",
      "Epoch 370: Eval Loss = 0.6826044\n",
      "Epoch 371: Eval Loss = 0.68261343\n",
      "Epoch 372: Eval Loss = 0.6826155\n",
      "Epoch 373: Eval Loss = 0.68257993\n",
      "Epoch 374: Eval Loss = 0.68251276\n",
      "Epoch 375: Eval Loss = 0.68242615\n",
      "Epoch 376: Eval Loss = 0.68238753\n",
      "Epoch 377: Eval Loss = 0.68235093\n",
      "Epoch 378: Eval Loss = 0.6822933\n",
      "Epoch 379: Eval Loss = 0.68222666\n",
      "Epoch 380: Eval Loss = 0.68218887\n",
      "Epoch 381: Eval Loss = 0.6821839\n",
      "Epoch 382: Eval Loss = 0.6821736\n",
      "Epoch 383: Eval Loss = 0.682154\n",
      "Epoch 384: Eval Loss = 0.6821316\n",
      "Epoch 385: Eval Loss = 0.68208975\n",
      "Epoch 386: Eval Loss = 0.6820316\n",
      "Epoch 387: Eval Loss = 0.6819681\n",
      "Epoch 388: Eval Loss = 0.68192095\n",
      "Epoch 389: Eval Loss = 0.6818726\n",
      "Epoch 390: Eval Loss = 0.68184525\n",
      "Epoch 391: Eval Loss = 0.6817738\n",
      "Epoch 392: Eval Loss = 0.68172175\n",
      "Epoch 393: Eval Loss = 0.681648\n",
      "Epoch 394: Eval Loss = 0.6815957\n",
      "Epoch 395: Eval Loss = 0.68155026\n",
      "Epoch 396: Eval Loss = 0.68151766\n",
      "Epoch 397: Eval Loss = 0.6815093\n",
      "Epoch 398: Eval Loss = 0.6815401\n",
      "Epoch 399: Eval Loss = 0.6815369\n",
      "Epoch 400: Eval Loss = 0.6815305\n",
      "Epoch 401: Eval Loss = 0.6815715\n",
      "Epoch 402: Eval Loss = 0.6815769\n",
      "Epoch 403: Eval Loss = 0.6815541\n",
      "Epoch 404: Eval Loss = 0.6815674\n",
      "Epoch 405: Eval Loss = 0.6816053\n",
      "Epoch 406: Eval Loss = 0.68163663\n",
      "Epoch 407: Eval Loss = 0.68165433\n",
      "Epoch 408: Eval Loss = 0.6816912\n",
      "Epoch 409: Eval Loss = 0.6817474\n",
      "Epoch 410: Eval Loss = 0.6817676\n",
      "Epoch 411: Eval Loss = 0.6818047\n",
      "Epoch 412: Eval Loss = 0.6818287\n",
      "Epoch 413: Eval Loss = 0.6818197\n",
      "Epoch 414: Eval Loss = 0.68181247\n",
      "Epoch 415: Eval Loss = 0.68180346\n",
      "Epoch 416: Eval Loss = 0.68180823\n",
      "Epoch 417: Eval Loss = 0.6817839\n",
      "Epoch 418: Eval Loss = 0.681762\n",
      "Epoch 419: Eval Loss = 0.681733\n",
      "Epoch 420: Eval Loss = 0.6817028\n",
      "Epoch 421: Eval Loss = 0.68166184\n",
      "Epoch 422: Eval Loss = 0.6816599\n",
      "Epoch 423: Eval Loss = 0.6816717\n",
      "Epoch 424: Eval Loss = 0.6816662\n",
      "Epoch 425: Eval Loss = 0.6816876\n",
      "Epoch 426: Eval Loss = 0.681694\n",
      "Epoch 427: Eval Loss = 0.6816921\n",
      "Epoch 428: Eval Loss = 0.6816818\n",
      "Epoch 429: Eval Loss = 0.681682\n",
      "Epoch 430: Eval Loss = 0.68165433\n",
      "Epoch 431: Eval Loss = 0.68163824\n",
      "Epoch 432: Eval Loss = 0.6816319\n",
      "Epoch 433: Eval Loss = 0.6816205\n",
      "Epoch 434: Eval Loss = 0.68158704\n",
      "Epoch 435: Eval Loss = 0.6815682\n",
      "Epoch 436: Eval Loss = 0.6815881\n",
      "Epoch 437: Eval Loss = 0.68159705\n",
      "Epoch 438: Eval Loss = 0.6816278\n",
      "Epoch 439: Eval Loss = 0.6815956\n",
      "Epoch 440: Eval Loss = 0.6815574\n",
      "Epoch 441: Eval Loss = 0.6814769\n",
      "Epoch 442: Eval Loss = 0.6814289\n",
      "Epoch 443: Eval Loss = 0.68138933\n",
      "Epoch 444: Eval Loss = 0.6813566\n",
      "Epoch 445: Eval Loss = 0.6813039\n",
      "Epoch 446: Eval Loss = 0.6812322\n",
      "Epoch 447: Eval Loss = 0.6811893\n",
      "Epoch 448: Eval Loss = 0.68113595\n",
      "Epoch 449: Eval Loss = 0.68110955\n",
      "Epoch 450: Eval Loss = 0.681062\n",
      "Epoch 451: Eval Loss = 0.6810164\n",
      "Epoch 452: Eval Loss = 0.68093926\n",
      "Epoch 453: Eval Loss = 0.680869\n",
      "Epoch 454: Eval Loss = 0.6807995\n",
      "Epoch 455: Eval Loss = 0.6807428\n",
      "Epoch 456: Eval Loss = 0.68073225\n",
      "Epoch 457: Eval Loss = 0.68071383\n",
      "Epoch 458: Eval Loss = 0.68068534\n",
      "Epoch 459: Eval Loss = 0.68065417\n",
      "Epoch 460: Eval Loss = 0.68068933\n",
      "Epoch 461: Eval Loss = 0.68071747\n",
      "Epoch 462: Eval Loss = 0.6807596\n",
      "Epoch 463: Eval Loss = 0.6807859\n",
      "Epoch 464: Eval Loss = 0.6807934\n",
      "Epoch 465: Eval Loss = 0.6807444\n",
      "Epoch 466: Eval Loss = 0.68072313\n",
      "Epoch 467: Eval Loss = 0.68071127\n",
      "Epoch 468: Eval Loss = 0.6806984\n",
      "Epoch 469: Eval Loss = 0.68067604\n",
      "Epoch 470: Eval Loss = 0.6806604\n",
      "Epoch 471: Eval Loss = 0.6806529\n",
      "Epoch 472: Eval Loss = 0.6806508\n",
      "Epoch 473: Eval Loss = 0.68063253\n",
      "Epoch 474: Eval Loss = 0.68062097\n",
      "Epoch 475: Eval Loss = 0.68061393\n",
      "Epoch 476: Eval Loss = 0.6806279\n",
      "Epoch 477: Eval Loss = 0.680617\n",
      "Epoch 478: Eval Loss = 0.6806077\n",
      "Epoch 479: Eval Loss = 0.6806014\n",
      "Epoch 480: Eval Loss = 0.68059736\n",
      "Epoch 481: Eval Loss = 0.6805945\n",
      "Epoch 482: Eval Loss = 0.6805843\n",
      "Epoch 483: Eval Loss = 0.68056816\n",
      "Epoch 484: Eval Loss = 0.68052816\n",
      "Epoch 485: Eval Loss = 0.6804941\n",
      "Epoch 486: Eval Loss = 0.68048537\n",
      "Epoch 487: Eval Loss = 0.6804685\n",
      "Epoch 488: Eval Loss = 0.6804506\n",
      "Epoch 489: Eval Loss = 0.6804292\n",
      "Epoch 490: Eval Loss = 0.6803887\n",
      "Epoch 491: Eval Loss = 0.6803734\n",
      "Epoch 492: Eval Loss = 0.6804111\n",
      "Epoch 493: Eval Loss = 0.68044907\n",
      "Epoch 494: Eval Loss = 0.68046945\n",
      "Epoch 495: Eval Loss = 0.6805136\n",
      "Epoch 496: Eval Loss = 0.6805692\n",
      "Epoch 497: Eval Loss = 0.6805845\n",
      "Epoch 498: Eval Loss = 0.68062705\n",
      "Epoch 499: Eval Loss = 0.68068975\n",
      "Epoch 500: Eval Loss = 0.68073785\n",
      "Epoch 501: Eval Loss = 0.6807965\n",
      "Epoch 502: Eval Loss = 0.6808564\n",
      "Epoch 503: Eval Loss = 0.68087953\n",
      "Epoch 504: Eval Loss = 0.68090117\n",
      "Epoch 505: Eval Loss = 0.68095297\n",
      "Epoch 506: Eval Loss = 0.6809974\n",
      "Epoch 507: Eval Loss = 0.6810014\n",
      "Epoch 508: Eval Loss = 0.6810208\n",
      "Epoch 509: Eval Loss = 0.68104607\n",
      "Epoch 510: Eval Loss = 0.6810711\n",
      "Epoch 511: Eval Loss = 0.6810439\n",
      "Epoch 512: Eval Loss = 0.6810167\n",
      "Epoch 513: Eval Loss = 0.6810444\n",
      "Epoch 514: Eval Loss = 0.6810508\n",
      "Epoch 515: Eval Loss = 0.6810671\n",
      "Epoch 516: Eval Loss = 0.6810579\n",
      "Epoch 517: Eval Loss = 0.68103766\n",
      "Epoch 518: Eval Loss = 0.68103236\n",
      "Epoch 519: Eval Loss = 0.6810058\n",
      "Epoch 520: Eval Loss = 0.68093985\n",
      "Epoch 521: Eval Loss = 0.6808486\n",
      "Epoch 522: Eval Loss = 0.68076426\n",
      "Epoch 523: Eval Loss = 0.6807103\n",
      "Epoch 524: Eval Loss = 0.6806434\n",
      "Epoch 525: Eval Loss = 0.68060654\n",
      "Epoch 526: Eval Loss = 0.68055093\n",
      "Epoch 527: Eval Loss = 0.6805215\n",
      "Epoch 528: Eval Loss = 0.6804971\n",
      "Epoch 529: Eval Loss = 0.6804313\n",
      "Epoch 530: Eval Loss = 0.68035537\n",
      "Epoch 531: Eval Loss = 0.68030596\n",
      "Epoch 532: Eval Loss = 0.68022275\n",
      "Epoch 533: Eval Loss = 0.6801155\n",
      "Epoch 534: Eval Loss = 0.6800219\n",
      "Epoch 535: Eval Loss = 0.6799253\n",
      "Epoch 536: Eval Loss = 0.67981863\n",
      "Epoch 537: Eval Loss = 0.6797543\n",
      "Epoch 538: Eval Loss = 0.6796908\n",
      "Epoch 539: Eval Loss = 0.67967004\n",
      "Epoch 540: Eval Loss = 0.6796744\n",
      "Epoch 541: Eval Loss = 0.6796968\n",
      "Epoch 542: Eval Loss = 0.67969483\n",
      "Epoch 543: Eval Loss = 0.6797223\n",
      "Epoch 544: Eval Loss = 0.6797491\n",
      "Epoch 545: Eval Loss = 0.6797955\n",
      "Epoch 546: Eval Loss = 0.67984736\n",
      "Epoch 547: Eval Loss = 0.6798923\n",
      "Epoch 548: Eval Loss = 0.6799235\n",
      "Epoch 549: Eval Loss = 0.6799462\n",
      "Epoch 550: Eval Loss = 0.6799769\n",
      "Epoch 551: Eval Loss = 0.67996764\n",
      "Epoch 552: Eval Loss = 0.6799791\n",
      "Epoch 553: Eval Loss = 0.6800491\n",
      "Epoch 554: Eval Loss = 0.6800927\n",
      "Epoch 555: Eval Loss = 0.6801769\n",
      "Epoch 556: Eval Loss = 0.6802565\n",
      "Epoch 557: Eval Loss = 0.6803185\n",
      "Epoch 558: Eval Loss = 0.6803826\n",
      "Epoch 559: Eval Loss = 0.68046075\n",
      "Epoch 560: Eval Loss = 0.680539\n",
      "Epoch 561: Eval Loss = 0.68064135\n",
      "Epoch 562: Eval Loss = 0.6807053\n",
      "Epoch 563: Eval Loss = 0.6807851\n",
      "Epoch 564: Eval Loss = 0.68086416\n",
      "Epoch 565: Eval Loss = 0.68093264\n",
      "Epoch 566: Eval Loss = 0.68101066\n",
      "Epoch 567: Eval Loss = 0.6810936\n",
      "Epoch 568: Eval Loss = 0.6811596\n",
      "Epoch 569: Eval Loss = 0.68122756\n",
      "Epoch 570: Eval Loss = 0.68128186\n",
      "Epoch 571: Eval Loss = 0.68133116\n",
      "Epoch 572: Eval Loss = 0.6813787\n",
      "Epoch 573: Eval Loss = 0.6814172\n",
      "Epoch 574: Eval Loss = 0.68143225\n",
      "Epoch 575: Eval Loss = 0.68144137\n",
      "Epoch 576: Eval Loss = 0.68144226\n",
      "Epoch 577: Eval Loss = 0.6814467\n",
      "Epoch 578: Eval Loss = 0.6814449\n",
      "Epoch 579: Eval Loss = 0.6814539\n",
      "Epoch 580: Eval Loss = 0.68144035\n",
      "Epoch 581: Eval Loss = 0.6814178\n",
      "Epoch 582: Eval Loss = 0.6813945\n",
      "Epoch 583: Eval Loss = 0.6813764\n",
      "Epoch 584: Eval Loss = 0.68138003\n",
      "Epoch 585: Eval Loss = 0.6814014\n",
      "Epoch 586: Eval Loss = 0.68140167\n",
      "Epoch 587: Eval Loss = 0.6813734\n",
      "Epoch 588: Eval Loss = 0.6813294\n",
      "Epoch 589: Eval Loss = 0.68132585\n",
      "Epoch 590: Eval Loss = 0.6812731\n",
      "Epoch 591: Eval Loss = 0.68126714\n",
      "Epoch 592: Eval Loss = 0.68128484\n",
      "Epoch 593: Eval Loss = 0.6813105\n",
      "Epoch 594: Eval Loss = 0.681285\n",
      "Epoch 595: Eval Loss = 0.6812904\n",
      "Epoch 596: Eval Loss = 0.6812692\n",
      "Epoch 597: Eval Loss = 0.68126416\n",
      "Epoch 598: Eval Loss = 0.6812775\n",
      "Epoch 599: Eval Loss = 0.68129134\n",
      "Epoch 600: Eval Loss = 0.6812984\n",
      "Epoch 601: Eval Loss = 0.6812807\n",
      "Epoch 602: Eval Loss = 0.6812805\n",
      "Epoch 603: Eval Loss = 0.6812732\n",
      "Epoch 604: Eval Loss = 0.681272\n",
      "Epoch 605: Eval Loss = 0.6812893\n",
      "Epoch 606: Eval Loss = 0.68127275\n",
      "Epoch 607: Eval Loss = 0.6812738\n",
      "Epoch 608: Eval Loss = 0.6812379\n",
      "Epoch 609: Eval Loss = 0.681193\n",
      "Epoch 610: Eval Loss = 0.68116075\n",
      "Epoch 611: Eval Loss = 0.6811308\n",
      "Epoch 612: Eval Loss = 0.6811103\n",
      "Epoch 613: Eval Loss = 0.6811041\n",
      "Epoch 614: Eval Loss = 0.6811016\n",
      "Epoch 615: Eval Loss = 0.68109584\n",
      "Epoch 616: Eval Loss = 0.68109095\n",
      "Epoch 617: Eval Loss = 0.6810524\n",
      "Epoch 618: Eval Loss = 0.6810521\n",
      "Epoch 619: Eval Loss = 0.6810453\n",
      "Epoch 620: Eval Loss = 0.6810086\n",
      "Epoch 621: Eval Loss = 0.6809821\n",
      "Epoch 622: Eval Loss = 0.68094563\n",
      "Epoch 623: Eval Loss = 0.68093926\n",
      "Epoch 624: Eval Loss = 0.68095344\n",
      "Epoch 625: Eval Loss = 0.6809414\n",
      "Epoch 626: Eval Loss = 0.6808962\n",
      "Epoch 627: Eval Loss = 0.6808467\n",
      "Epoch 628: Eval Loss = 0.6808245\n",
      "Epoch 629: Eval Loss = 0.6807553\n",
      "Epoch 630: Eval Loss = 0.680678\n",
      "Epoch 631: Eval Loss = 0.68063074\n",
      "Epoch 632: Eval Loss = 0.6805584\n",
      "Epoch 633: Eval Loss = 0.6805114\n",
      "Epoch 634: Eval Loss = 0.68045586\n",
      "Epoch 635: Eval Loss = 0.6804403\n",
      "Epoch 636: Eval Loss = 0.68041366\n",
      "Epoch 637: Eval Loss = 0.6803753\n",
      "Epoch 638: Eval Loss = 0.68036425\n",
      "Epoch 639: Eval Loss = 0.6803328\n",
      "Epoch 640: Eval Loss = 0.68032974\n",
      "Epoch 641: Eval Loss = 0.6803095\n",
      "Epoch 642: Eval Loss = 0.6802636\n",
      "Epoch 643: Eval Loss = 0.68023163\n",
      "Epoch 644: Eval Loss = 0.68018854\n",
      "Epoch 645: Eval Loss = 0.68015397\n",
      "Epoch 646: Eval Loss = 0.6801093\n",
      "Epoch 647: Eval Loss = 0.6800663\n",
      "Epoch 648: Eval Loss = 0.6800303\n",
      "Epoch 649: Eval Loss = 0.6800447\n",
      "Epoch 650: Eval Loss = 0.68008214\n",
      "Epoch 651: Eval Loss = 0.6800628\n",
      "Epoch 652: Eval Loss = 0.68006414\n",
      "Epoch 653: Eval Loss = 0.68002707\n",
      "Epoch 654: Eval Loss = 0.6800071\n",
      "Epoch 655: Eval Loss = 0.6799693\n",
      "Epoch 656: Eval Loss = 0.67995054\n",
      "Epoch 657: Eval Loss = 0.6798989\n",
      "Epoch 658: Eval Loss = 0.67991287\n",
      "Epoch 659: Eval Loss = 0.679918\n",
      "Epoch 660: Eval Loss = 0.6798864\n",
      "Epoch 661: Eval Loss = 0.6798022\n",
      "Epoch 662: Eval Loss = 0.6797471\n",
      "Epoch 663: Eval Loss = 0.67969894\n",
      "Epoch 664: Eval Loss = 0.6796319\n",
      "Epoch 665: Eval Loss = 0.67959845\n",
      "Epoch 666: Eval Loss = 0.679536\n",
      "Epoch 667: Eval Loss = 0.6794749\n",
      "Epoch 668: Eval Loss = 0.6794477\n",
      "Epoch 669: Eval Loss = 0.67940384\n",
      "Epoch 670: Eval Loss = 0.6793558\n",
      "Epoch 671: Eval Loss = 0.67931825\n",
      "Epoch 672: Eval Loss = 0.6792265\n",
      "Epoch 673: Eval Loss = 0.679158\n",
      "Epoch 674: Eval Loss = 0.6791295\n",
      "Epoch 675: Eval Loss = 0.67910737\n",
      "Epoch 676: Eval Loss = 0.6791227\n",
      "Epoch 677: Eval Loss = 0.67915434\n",
      "Epoch 678: Eval Loss = 0.67915094\n",
      "Epoch 679: Eval Loss = 0.6791404\n",
      "Epoch 680: Eval Loss = 0.6791479\n",
      "Epoch 681: Eval Loss = 0.67911565\n",
      "Epoch 682: Eval Loss = 0.67910457\n",
      "Epoch 683: Eval Loss = 0.6790749\n",
      "Epoch 684: Eval Loss = 0.6790289\n",
      "Epoch 685: Eval Loss = 0.67902154\n",
      "Epoch 686: Eval Loss = 0.67900574\n",
      "Epoch 687: Eval Loss = 0.6790113\n",
      "Epoch 688: Eval Loss = 0.67903256\n",
      "Epoch 689: Eval Loss = 0.67906463\n",
      "Epoch 690: Eval Loss = 0.67913413\n",
      "Epoch 691: Eval Loss = 0.6791726\n",
      "Epoch 692: Eval Loss = 0.6791982\n",
      "Epoch 693: Eval Loss = 0.679254\n",
      "Epoch 694: Eval Loss = 0.6792762\n",
      "Epoch 695: Eval Loss = 0.6792831\n",
      "Epoch 696: Eval Loss = 0.67925525\n",
      "Epoch 697: Eval Loss = 0.6792813\n",
      "Epoch 698: Eval Loss = 0.6792734\n",
      "Epoch 699: Eval Loss = 0.679284\n",
      "Epoch 700: Eval Loss = 0.67930186\n",
      "Epoch 701: Eval Loss = 0.67932564\n",
      "Epoch 702: Eval Loss = 0.6793605\n",
      "Epoch 703: Eval Loss = 0.67936134\n",
      "Epoch 704: Eval Loss = 0.67934054\n",
      "Epoch 705: Eval Loss = 0.67934555\n",
      "Epoch 706: Eval Loss = 0.6793654\n",
      "Epoch 707: Eval Loss = 0.6793695\n",
      "Epoch 708: Eval Loss = 0.67937285\n",
      "Epoch 709: Eval Loss = 0.6794043\n",
      "Epoch 710: Eval Loss = 0.6794321\n",
      "Epoch 711: Eval Loss = 0.6794828\n",
      "Epoch 712: Eval Loss = 0.67951185\n",
      "Epoch 713: Eval Loss = 0.67954576\n",
      "Epoch 714: Eval Loss = 0.67953163\n",
      "Epoch 715: Eval Loss = 0.67956924\n",
      "Epoch 716: Eval Loss = 0.67961687\n",
      "Epoch 717: Eval Loss = 0.6796842\n",
      "Epoch 718: Eval Loss = 0.67976195\n",
      "Epoch 719: Eval Loss = 0.67981124\n",
      "Epoch 720: Eval Loss = 0.67984086\n",
      "Epoch 721: Eval Loss = 0.67986274\n",
      "Epoch 722: Eval Loss = 0.6799105\n",
      "Epoch 723: Eval Loss = 0.6799523\n",
      "Epoch 724: Eval Loss = 0.67996347\n",
      "Epoch 725: Eval Loss = 0.6799409\n",
      "Epoch 726: Eval Loss = 0.67991376\n",
      "Epoch 727: Eval Loss = 0.67987573\n",
      "Epoch 728: Eval Loss = 0.6798733\n",
      "Epoch 729: Eval Loss = 0.67988664\n",
      "Epoch 730: Eval Loss = 0.67988867\n",
      "Epoch 731: Eval Loss = 0.6798927\n",
      "Epoch 732: Eval Loss = 0.6799243\n",
      "Epoch 733: Eval Loss = 0.679984\n",
      "Epoch 734: Eval Loss = 0.6800313\n",
      "Epoch 735: Eval Loss = 0.6800981\n",
      "Epoch 736: Eval Loss = 0.68017423\n",
      "Epoch 737: Eval Loss = 0.68025076\n",
      "Epoch 738: Eval Loss = 0.6803273\n",
      "Epoch 739: Eval Loss = 0.6803686\n",
      "Epoch 740: Eval Loss = 0.68034256\n",
      "Epoch 741: Eval Loss = 0.6803783\n",
      "Epoch 742: Eval Loss = 0.68042946\n",
      "Epoch 743: Eval Loss = 0.68042064\n",
      "Epoch 744: Eval Loss = 0.6804373\n",
      "Epoch 745: Eval Loss = 0.6804458\n",
      "Epoch 746: Eval Loss = 0.6804505\n",
      "Epoch 747: Eval Loss = 0.6805069\n",
      "Epoch 748: Eval Loss = 0.6805349\n",
      "Epoch 749: Eval Loss = 0.6805534\n",
      "Epoch 750: Eval Loss = 0.68059886\n",
      "Epoch 751: Eval Loss = 0.68062264\n",
      "Epoch 752: Eval Loss = 0.6805987\n",
      "Epoch 753: Eval Loss = 0.68054914\n",
      "Epoch 754: Eval Loss = 0.68050605\n",
      "Epoch 755: Eval Loss = 0.6804882\n",
      "Epoch 756: Eval Loss = 0.68048364\n",
      "Epoch 757: Eval Loss = 0.68047166\n",
      "Epoch 758: Eval Loss = 0.6804565\n",
      "Epoch 759: Eval Loss = 0.680463\n",
      "Epoch 760: Eval Loss = 0.6805121\n",
      "Epoch 761: Eval Loss = 0.6805526\n",
      "Epoch 762: Eval Loss = 0.6805689\n",
      "Epoch 763: Eval Loss = 0.6805362\n",
      "Epoch 764: Eval Loss = 0.68053466\n",
      "Epoch 765: Eval Loss = 0.6805551\n",
      "Epoch 766: Eval Loss = 0.6805608\n",
      "Epoch 767: Eval Loss = 0.68058455\n",
      "Epoch 768: Eval Loss = 0.6806122\n",
      "Epoch 769: Eval Loss = 0.6806213\n",
      "Epoch 770: Eval Loss = 0.68063\n",
      "Epoch 771: Eval Loss = 0.68061006\n",
      "Epoch 772: Eval Loss = 0.680567\n",
      "Epoch 773: Eval Loss = 0.68057203\n",
      "Epoch 774: Eval Loss = 0.6805564\n",
      "Epoch 775: Eval Loss = 0.6805131\n",
      "Epoch 776: Eval Loss = 0.6804494\n",
      "Epoch 777: Eval Loss = 0.68040156\n",
      "Epoch 778: Eval Loss = 0.6803511\n",
      "Epoch 779: Eval Loss = 0.68028784\n",
      "Epoch 780: Eval Loss = 0.68023574\n",
      "Epoch 781: Eval Loss = 0.6801862\n",
      "Epoch 782: Eval Loss = 0.68009466\n",
      "Epoch 783: Eval Loss = 0.6800044\n",
      "Epoch 784: Eval Loss = 0.6799289\n",
      "Epoch 785: Eval Loss = 0.6798787\n",
      "Epoch 786: Eval Loss = 0.6798212\n",
      "Epoch 787: Eval Loss = 0.679791\n",
      "Epoch 788: Eval Loss = 0.6798169\n",
      "Epoch 789: Eval Loss = 0.6798732\n",
      "Epoch 790: Eval Loss = 0.679929\n",
      "Epoch 791: Eval Loss = 0.6799897\n",
      "Epoch 792: Eval Loss = 0.68005747\n",
      "Epoch 793: Eval Loss = 0.6800716\n",
      "Epoch 794: Eval Loss = 0.6801094\n",
      "Epoch 795: Eval Loss = 0.6801366\n",
      "Epoch 796: Eval Loss = 0.6801717\n",
      "Epoch 797: Eval Loss = 0.6802409\n",
      "Epoch 798: Eval Loss = 0.68029755\n",
      "Epoch 799: Eval Loss = 0.680341\n",
      "Epoch 800: Eval Loss = 0.6804091\n",
      "Epoch 801: Eval Loss = 0.6804221\n",
      "Epoch 802: Eval Loss = 0.6804633\n",
      "Epoch 803: Eval Loss = 0.6804941\n",
      "Epoch 804: Eval Loss = 0.6805397\n",
      "Epoch 805: Eval Loss = 0.6806\n",
      "Epoch 806: Eval Loss = 0.6806434\n",
      "Epoch 807: Eval Loss = 0.6806624\n",
      "Epoch 808: Eval Loss = 0.6806651\n",
      "Epoch 809: Eval Loss = 0.6806565\n",
      "Epoch 810: Eval Loss = 0.68064547\n",
      "Epoch 811: Eval Loss = 0.6806504\n",
      "Epoch 812: Eval Loss = 0.6806738\n",
      "Epoch 813: Eval Loss = 0.6806905\n",
      "Epoch 814: Eval Loss = 0.6806902\n",
      "Epoch 815: Eval Loss = 0.6806183\n",
      "Epoch 816: Eval Loss = 0.6805401\n",
      "Epoch 817: Eval Loss = 0.68047297\n",
      "Epoch 818: Eval Loss = 0.6803553\n",
      "Epoch 819: Eval Loss = 0.68024313\n",
      "Epoch 820: Eval Loss = 0.6801613\n",
      "Epoch 821: Eval Loss = 0.6800674\n",
      "Epoch 822: Eval Loss = 0.6799793\n",
      "Epoch 823: Eval Loss = 0.67990565\n",
      "Epoch 824: Eval Loss = 0.679825\n",
      "Epoch 825: Eval Loss = 0.6797962\n",
      "Epoch 826: Eval Loss = 0.67977965\n",
      "Epoch 827: Eval Loss = 0.6797697\n",
      "Epoch 828: Eval Loss = 0.67971337\n",
      "Epoch 829: Eval Loss = 0.67964727\n",
      "Epoch 830: Eval Loss = 0.6796381\n",
      "Epoch 831: Eval Loss = 0.67962563\n",
      "Epoch 832: Eval Loss = 0.67963624\n",
      "Epoch 833: Eval Loss = 0.6796091\n",
      "Epoch 834: Eval Loss = 0.67957187\n",
      "Epoch 835: Eval Loss = 0.6795588\n",
      "Epoch 836: Eval Loss = 0.6795701\n",
      "Epoch 837: Eval Loss = 0.67959297\n",
      "Epoch 838: Eval Loss = 0.6796107\n",
      "Epoch 839: Eval Loss = 0.6796458\n",
      "Epoch 840: Eval Loss = 0.6796665\n",
      "Epoch 841: Eval Loss = 0.6797082\n",
      "Epoch 842: Eval Loss = 0.67972517\n",
      "Epoch 843: Eval Loss = 0.6797242\n",
      "Epoch 844: Eval Loss = 0.6797281\n",
      "Epoch 845: Eval Loss = 0.67975175\n",
      "Epoch 846: Eval Loss = 0.6797696\n",
      "Epoch 847: Eval Loss = 0.6798046\n",
      "Epoch 848: Eval Loss = 0.67983973\n",
      "Epoch 849: Eval Loss = 0.6798957\n",
      "Epoch 850: Eval Loss = 0.6799363\n",
      "Epoch 851: Eval Loss = 0.6799742\n",
      "Epoch 852: Eval Loss = 0.6800209\n",
      "Epoch 853: Eval Loss = 0.680093\n",
      "Epoch 854: Eval Loss = 0.68018484\n",
      "Epoch 855: Eval Loss = 0.68027145\n",
      "Epoch 856: Eval Loss = 0.68033195\n",
      "Epoch 857: Eval Loss = 0.68037\n",
      "Epoch 858: Eval Loss = 0.68037486\n",
      "Epoch 859: Eval Loss = 0.6803283\n",
      "Epoch 860: Eval Loss = 0.6802881\n",
      "Epoch 861: Eval Loss = 0.68025094\n",
      "Epoch 862: Eval Loss = 0.68022215\n",
      "Epoch 863: Eval Loss = 0.6802096\n",
      "Epoch 864: Eval Loss = 0.6802148\n",
      "Epoch 865: Eval Loss = 0.6802256\n",
      "Epoch 866: Eval Loss = 0.6801921\n",
      "Epoch 867: Eval Loss = 0.6802128\n",
      "Epoch 868: Eval Loss = 0.68023336\n",
      "Epoch 869: Eval Loss = 0.68027616\n",
      "Epoch 870: Eval Loss = 0.6802881\n",
      "Epoch 871: Eval Loss = 0.6802818\n",
      "Epoch 872: Eval Loss = 0.6802671\n",
      "Epoch 873: Eval Loss = 0.6802949\n",
      "Epoch 874: Eval Loss = 0.68032515\n",
      "Epoch 875: Eval Loss = 0.68035257\n",
      "Epoch 876: Eval Loss = 0.68042046\n",
      "Epoch 877: Eval Loss = 0.68042237\n",
      "Epoch 878: Eval Loss = 0.6804239\n",
      "Epoch 879: Eval Loss = 0.6804558\n",
      "Epoch 880: Eval Loss = 0.68043303\n",
      "Epoch 881: Eval Loss = 0.68040246\n",
      "Epoch 882: Eval Loss = 0.68035364\n",
      "Epoch 883: Eval Loss = 0.6803055\n",
      "Epoch 884: Eval Loss = 0.68020827\n",
      "Epoch 885: Eval Loss = 0.6801613\n",
      "Epoch 886: Eval Loss = 0.6801422\n",
      "Epoch 887: Eval Loss = 0.68009895\n",
      "Epoch 888: Eval Loss = 0.68002784\n",
      "Epoch 889: Eval Loss = 0.67994314\n",
      "Epoch 890: Eval Loss = 0.679861\n",
      "Epoch 891: Eval Loss = 0.67982644\n",
      "Epoch 892: Eval Loss = 0.6797097\n",
      "Epoch 893: Eval Loss = 0.67960656\n",
      "Epoch 894: Eval Loss = 0.6795224\n",
      "Epoch 895: Eval Loss = 0.679422\n",
      "Epoch 896: Eval Loss = 0.67931956\n",
      "Epoch 897: Eval Loss = 0.6792297\n",
      "Epoch 898: Eval Loss = 0.67912596\n",
      "Epoch 899: Eval Loss = 0.6790324\n",
      "Epoch 900: Eval Loss = 0.6789957\n",
      "Epoch 901: Eval Loss = 0.6789492\n",
      "Epoch 902: Eval Loss = 0.6788993\n",
      "Epoch 903: Eval Loss = 0.6788708\n",
      "Epoch 904: Eval Loss = 0.6788802\n",
      "Epoch 905: Eval Loss = 0.67882955\n",
      "Epoch 906: Eval Loss = 0.6787607\n",
      "Epoch 907: Eval Loss = 0.6787079\n",
      "Epoch 908: Eval Loss = 0.67866576\n",
      "Epoch 909: Eval Loss = 0.6785899\n",
      "Epoch 910: Eval Loss = 0.67851454\n",
      "Epoch 911: Eval Loss = 0.6784885\n",
      "Epoch 912: Eval Loss = 0.67843956\n",
      "Epoch 913: Eval Loss = 0.67839813\n",
      "Epoch 914: Eval Loss = 0.6784094\n",
      "Epoch 915: Eval Loss = 0.67837685\n",
      "Epoch 916: Eval Loss = 0.6783862\n",
      "Epoch 917: Eval Loss = 0.6783643\n",
      "Epoch 918: Eval Loss = 0.67832494\n",
      "Epoch 919: Eval Loss = 0.6782897\n",
      "Epoch 920: Eval Loss = 0.67824125\n",
      "Epoch 921: Eval Loss = 0.6782505\n",
      "Epoch 922: Eval Loss = 0.67825747\n",
      "Epoch 923: Eval Loss = 0.6782406\n",
      "Epoch 924: Eval Loss = 0.6782143\n",
      "Epoch 925: Eval Loss = 0.67818177\n",
      "Epoch 926: Eval Loss = 0.6781408\n",
      "Epoch 927: Eval Loss = 0.67810035\n",
      "Epoch 928: Eval Loss = 0.67806315\n",
      "Epoch 929: Eval Loss = 0.6780425\n",
      "Epoch 930: Eval Loss = 0.67801577\n",
      "Epoch 931: Eval Loss = 0.677991\n",
      "Epoch 932: Eval Loss = 0.6779627\n",
      "Epoch 933: Eval Loss = 0.67796564\n",
      "Epoch 934: Eval Loss = 0.67799294\n",
      "Epoch 935: Eval Loss = 0.67800987\n",
      "Epoch 936: Eval Loss = 0.6780052\n",
      "Epoch 937: Eval Loss = 0.6780586\n",
      "Epoch 938: Eval Loss = 0.67812365\n",
      "Epoch 939: Eval Loss = 0.6781637\n",
      "Epoch 940: Eval Loss = 0.67817056\n",
      "Epoch 941: Eval Loss = 0.67816836\n",
      "Epoch 942: Eval Loss = 0.67814666\n",
      "Epoch 943: Eval Loss = 0.6781745\n",
      "Epoch 944: Eval Loss = 0.6782189\n",
      "Epoch 945: Eval Loss = 0.6782689\n",
      "Epoch 946: Eval Loss = 0.6783078\n",
      "Epoch 947: Eval Loss = 0.6783163\n",
      "Epoch 948: Eval Loss = 0.67829233\n",
      "Epoch 949: Eval Loss = 0.67832077\n",
      "Epoch 950: Eval Loss = 0.67831683\n",
      "Epoch 951: Eval Loss = 0.6782921\n",
      "Epoch 952: Eval Loss = 0.67824644\n",
      "Epoch 953: Eval Loss = 0.67821175\n",
      "Epoch 954: Eval Loss = 0.6781739\n",
      "Epoch 955: Eval Loss = 0.6780978\n",
      "Epoch 956: Eval Loss = 0.6780115\n",
      "Epoch 957: Eval Loss = 0.6779366\n",
      "Epoch 958: Eval Loss = 0.6778851\n",
      "Epoch 959: Eval Loss = 0.6778248\n",
      "Epoch 960: Eval Loss = 0.67775184\n",
      "Epoch 961: Eval Loss = 0.67772746\n",
      "Epoch 962: Eval Loss = 0.67771906\n",
      "Epoch 963: Eval Loss = 0.67768526\n",
      "Epoch 964: Eval Loss = 0.67766845\n",
      "Epoch 965: Eval Loss = 0.67762315\n",
      "Epoch 966: Eval Loss = 0.67757696\n",
      "Epoch 967: Eval Loss = 0.67756075\n",
      "Epoch 968: Eval Loss = 0.6775008\n",
      "Epoch 969: Eval Loss = 0.67751783\n",
      "Epoch 970: Eval Loss = 0.6775052\n",
      "Epoch 971: Eval Loss = 0.6775186\n",
      "Epoch 972: Eval Loss = 0.6775617\n",
      "Epoch 973: Eval Loss = 0.6776064\n",
      "Epoch 974: Eval Loss = 0.6776689\n",
      "Epoch 975: Eval Loss = 0.6777418\n",
      "Epoch 976: Eval Loss = 0.6777877\n",
      "Epoch 977: Eval Loss = 0.6778771\n",
      "Epoch 978: Eval Loss = 0.6780193\n",
      "Epoch 979: Eval Loss = 0.6781414\n",
      "Epoch 980: Eval Loss = 0.6782497\n",
      "Epoch 981: Eval Loss = 0.6783809\n",
      "Epoch 982: Eval Loss = 0.67849493\n",
      "Epoch 983: Eval Loss = 0.6786184\n",
      "Epoch 984: Eval Loss = 0.6787362\n",
      "Epoch 985: Eval Loss = 0.6788519\n",
      "Epoch 986: Eval Loss = 0.67895806\n",
      "Epoch 987: Eval Loss = 0.67908597\n",
      "Epoch 988: Eval Loss = 0.6791851\n",
      "Epoch 989: Eval Loss = 0.67933327\n",
      "Epoch 990: Eval Loss = 0.6794252\n",
      "Epoch 991: Eval Loss = 0.67946357\n",
      "Epoch 992: Eval Loss = 0.6795583\n",
      "Epoch 993: Eval Loss = 0.67965335\n",
      "Epoch 994: Eval Loss = 0.6796842\n",
      "Epoch 995: Eval Loss = 0.6797357\n",
      "Epoch 996: Eval Loss = 0.6797499\n",
      "Epoch 997: Eval Loss = 0.67981577\n",
      "Epoch 998: Eval Loss = 0.67988145\n",
      "Epoch 999: Eval Loss = 0.67994654\n"
     ]
    }
   ],
   "source": [
    "net = FFDNN()\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "INFO:tensorflow:Restoring parameters from ./activity6.ckpt\n",
      "        YES       OBS        NO pred_bins  YES  OBS  NO targ_bins   tp   fp  \\\n",
      "0  0.557001  0.309277  0.133722       YES    1    0   0       YES  1.0  0.0   \n",
      "1  0.338974  0.479035  0.181991       OBS    1    0   0       YES  0.0  1.0   \n",
      "2  0.273580  0.431403  0.295017       OBS    1    0   0       YES  0.0  1.0   \n",
      "3  0.765355  0.079647  0.154998       YES    0    0   1        NO  0.0  1.0   \n",
      "4  0.641995  0.117322  0.240683       YES    1    0   0       YES  1.0  0.0   \n",
      "\n",
      "    fn  tp_YES  fp_YES  fn_YES  tp_OBS  fp_OBS  fn_OBS  tp_NO  fp_NO  fn_NO  \n",
      "0  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "1  1.0     0.0     0.0     1.0     0.0     1.0     0.0    0.0    0.0    0.0  \n",
      "2  1.0     0.0     0.0     1.0     0.0     1.0     0.0    0.0    0.0    0.0  \n",
      "3  1.0     0.0     1.0     0.0     0.0     0.0     0.0    0.0    0.0    1.0  \n",
      "4  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "INFO:tensorflow:Restoring parameters from ./activity6.ckpt\n",
      "        YES       OBS        NO pred_bins  YES  OBS  NO targ_bins   tp   fp  \\\n",
      "0  0.294286  0.223029  0.482685        NO    1    0   0       YES  0.0  1.0   \n",
      "1  0.113487  0.093738  0.792776        NO    0    0   1        NO  1.0  0.0   \n",
      "2  0.384927  0.315386  0.299687       YES    1    0   0       YES  1.0  0.0   \n",
      "3  0.721359  0.205041  0.073600       YES    1    0   0       YES  1.0  0.0   \n",
      "4  0.208010  0.184648  0.607343        NO    0    1   0       OBS  0.0  1.0   \n",
      "\n",
      "    fn  tp_YES  fp_YES  fn_YES  tp_OBS  fp_OBS  fn_OBS  tp_NO  fp_NO  fn_NO  \n",
      "0  1.0     0.0     0.0     1.0     0.0     0.0     0.0    0.0    1.0    0.0  \n",
      "1  0.0     0.0     0.0     0.0     0.0     0.0     0.0    1.0    0.0    0.0  \n",
      "2  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "3  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "4  1.0     0.0     0.0     0.0     0.0     0.0     1.0    0.0    1.0    0.0  \n",
      "(100, 20)\n"
     ]
    }
   ],
   "source": [
    "details, details_all = test(net)\n",
    "print(details.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SUMMARY\n",
      "YES                                                     27.122\n",
      "OBS                                                    22.0452\n",
      "NO                                                     50.8329\n",
      "pred_bins    YESOBSOBSYESYESNOYESNONONONONOOBSNONONONONONOO...\n",
      "YES                                                         28\n",
      "OBS                                                         16\n",
      "NO                                                          56\n",
      "targ_bins    YESYESYESNOYESNOYESNONONOYESNONONONOYESYESNONO...\n",
      "tp                                                          73\n",
      "fp                                                          27\n",
      "fn                                                          27\n",
      "tp_YES                                                      15\n",
      "fp_YES                                                      10\n",
      "fn_YES                                                      13\n",
      "tp_OBS                                                       7\n",
      "fp_OBS                                                      10\n",
      "fn_OBS                                                       9\n",
      "tp_NO                                                       51\n",
      "fp_NO                                                        7\n",
      "fn_NO                                                        5\n",
      "dtype: object\n",
      "ALL SUMMARY\n",
      "YES                                                    258.162\n",
      "OBS                                                    219.243\n",
      "NO                                                     522.595\n",
      "pred_bins    NONOYESYESNONONONONONONONONONONOOBSNOYESNONONO...\n",
      "YES                                                        248\n",
      "OBS                                                        161\n",
      "NO                                                         591\n",
      "targ_bins    YESNOYESYESOBSNONONONONONONONONONOOBSNOYESNONO...\n",
      "tp                                                         782\n",
      "fp                                                         218\n",
      "fn                                                         218\n",
      "tp_YES                                                     136\n",
      "fp_YES                                                      63\n",
      "fn_YES                                                     112\n",
      "tp_OBS                                                     104\n",
      "fp_OBS                                                      87\n",
      "fn_OBS                                                      57\n",
      "tp_NO                                                      542\n",
      "fp_NO                                                       68\n",
      "fn_NO                                                       49\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "summaries_test = details.sum(axis=0)\n",
    "summaries_all = details_all.sum(axis=0)\n",
    "#summaries_test = calc_overall(summaries_test)\n",
    "print(\"TEST SUMMARY\")\n",
    "print(summaries_test)\n",
    "print(\"ALL SUMMARY\")\n",
    "print(summaries_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calc_recall_precision(summary, affix):\n",
    "    recall = summary['tp' + affix] / (summary['tp' + affix] + summary['fn' + affix])\n",
    "    precision = summary['tp' + affix] / (summary['tp' + affix] + summary['fp' + affix])\n",
    "    print(affix + ' recall: ' + str(recall) + ' ' + affix + ' precision: ' + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET METRICS\n",
      " recall: 0.73  precision: 0.73\n",
      "_YES recall: 0.535714285714 _YES precision: 0.6\n",
      "_NO recall: 0.910714285714 _NO precision: 0.879310344828\n",
      "_OBS recall: 0.4375 _OBS precision: 0.411764705882\n"
     ]
    }
   ],
   "source": [
    "print('TEST SET METRICS')\n",
    "calc_recall_precision(summaries_test, '')\n",
    "calc_recall_precision(summaries_test, '_YES')\n",
    "calc_recall_precision(summaries_test, '_NO')\n",
    "calc_recall_precision(summaries_test, '_OBS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DATA METRICS\n",
      " recall: 0.782  precision: 0.782\n",
      "_YES recall: 0.548387096774 _YES precision: 0.683417085427\n",
      "_NO recall: 0.917089678511 _NO precision: 0.888524590164\n",
      "_OBS recall: 0.645962732919 _OBS precision: 0.544502617801\n"
     ]
    }
   ],
   "source": [
    "print('ALL DATA METRICS')\n",
    "calc_recall_precision(summaries_all, '')\n",
    "calc_recall_precision(summaries_all, '_YES')\n",
    "calc_recall_precision(summaries_all, '_NO')\n",
    "calc_recall_precision(summaries_all, '_OBS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
