{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Chest Pain</th>\n",
       "      <th>Genereal level of tiredness</th>\n",
       "      <th>Pulse, resting</th>\n",
       "      <th>Blood Type</th>\n",
       "      <th>Heart disease mom/dad</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>Use of contact lenses</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>H�matokritv�rdi</th>\n",
       "      <th>EKG</th>\n",
       "      <th>Go to doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>Periodic</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0 pos</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>121</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>38</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>6</td>\n",
       "      <td>Often</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>0 pos</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>118</td>\n",
       "      <td>Y</td>\n",
       "      <td>Type 1</td>\n",
       "      <td>39</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>OBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>Periodic</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>B pos</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>154</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>41</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>Often</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>B pos</td>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>40</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>B pos</td>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>124</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>42</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender  Age Chest Pain  Genereal level of tiredness  Pulse, resting  \\\n",
       "0      M    4   Periodic                            4              59   \n",
       "1      M    6      Often                            8              80   \n",
       "2      F   15   Periodic                            0              67   \n",
       "3      M   15      Often                           10              69   \n",
       "4      F   17       None                            1              72   \n",
       "\n",
       "  Blood Type Heart disease mom/dad  Smoking  Cholesterol  Alcohol  BMI  \\\n",
       "0      0 pos                     N        0            1        6   22   \n",
       "1      0 pos                     N        0            6       10   35   \n",
       "2      B pos                     Y        4            1        0   22   \n",
       "3      B pos                     Y        6            1        0   22   \n",
       "4      B pos                     N        7            1        6   22   \n",
       "\n",
       "   Fitness Use of contact lenses Diabetes  H�matokritv�rdi           EKG  \\\n",
       "0      121                     N  Healthy               38  Anormalities   \n",
       "1      118                     Y   Type 1               39  Anormalities   \n",
       "2      154                     N  Healthy               41        Normal   \n",
       "3      150                     N  Healthy               40  Anormalities   \n",
       "4      124                     N  Healthy               42  Anormalities   \n",
       "\n",
       "  Go to doctor  \n",
       "0           NO  \n",
       "1          OBS  \n",
       "2           NO  \n",
       "3           NO  \n",
       "4           NO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Go to doctor_YES  Go to doctor_OBS  Go to doctor_NO\n",
      "0                 0                 0                1\n",
      "1                 0                 1                0\n",
      "2                 0                 0                1\n",
      "3                 0                 0                1\n",
      "4                 0                 0                1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "category_fields = ['Gender', 'Chest Pain', 'Blood Type', 'Heart disease mom/dad', 'Use of contact lenses', \n",
    "                   'Diabetes', 'EKG', 'Go to doctor']\n",
    "\n",
    "for each in category_fields:\n",
    "    dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    \n",
    "df = df.drop(category_fields, axis=1)\n",
    "\n",
    "pd_y = df[['Go to doctor_YES', 'Go to doctor_OBS', 'Go to doctor_NO']]\n",
    "pd_x = df.drop(['Go to doctor_YES', 'Go to doctor_OBS', 'Go to doctor_NO'], axis=1)\n",
    "print(pd_y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pd_x, pd_y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0)\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_test, y_test, \n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state=0)\n",
    "\n",
    "def chunk(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "train_xb, train_yb = list(chunk(X_train, 256)), list(chunk(y_train, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def hidden_layer(inputs, nodes, keep_rate, norm, training):\n",
    "    outputs = tf.layers.dense(inputs, nodes, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    if norm == 1:\n",
    "        outputs = tf.layers.batch_normalization(outputs, training=training)\n",
    "    outputs = tf.layers.dropout(outputs, 1-keep_rate, training=training)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_logits(net):\n",
    "    norm_input = tf.layers.batch_normalization(net.inputs_, training=net.training_)\n",
    "    hl = hidden_layer(norm_input, 180, net.krate, 1, net.training_)\n",
    "    hl = hidden_layer(hl, 360, net.krate, 1, net.training_)\n",
    "    hl = hidden_layer(hl, 180, net.krate, 1, net.training_)\n",
    "    logits = hidden_layer(hl, 3, net.krate, 1, net.training_)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_cost(logits, targets):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets),name='cross_entropy')\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_softmax(logits):\n",
    "    return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_cross_entropy(cost):\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.summary.scalar('cross_entropy', cost)\n",
    "        return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def set_hypertune_param(cost):\n",
    "    with tf.name_scope('hypertune'):\n",
    "        hypertune = tf.summary.scalar('training/hptuning/metric', cost)\n",
    "        return hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_optimizer(cost, lr):\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, targets):\n",
    "    predictions_pd = pd.DataFrame(pred[:,:], columns=['YES', 'OBS', 'NO'])\n",
    "    targets_pd = pd.DataFrame(targets[:,:], columns=['YES', 'OBS', 'NO'])\n",
    "    predictions_pd['pred_bins'] = predictions_pd.idxmax(axis=1)\n",
    "    targets_pd['targ_bins'] = targets_pd.idxmax(axis=1)\n",
    "    test_pd = pd.concat([predictions_pd, targets_pd], axis=1)\n",
    "    test_pd['tp'] = 0\n",
    "    test_pd['fp'] = 0\n",
    "    test_pd['fn'] = 0\n",
    "\n",
    "    for each in ['YES', 'OBS', 'NO']:\n",
    "        test_pd['tp_' + each] = test_pd.apply(\n",
    "            lambda x: 1 if x['pred_bins'] == each and x['targ_bins'] == each else 0, axis=1).astype(float)\n",
    "        test_pd['tp'] += test_pd['tp_' + each]\n",
    "    \n",
    "        test_pd['fp_' + each] = test_pd.apply(\n",
    "            lambda x: 1 if x['pred_bins'] == each and x['targ_bins'] != each else 0, axis=1).astype(float)\n",
    "        test_pd['fp'] += test_pd['fp_' + each]\n",
    "\n",
    "        test_pd['fn_' + each] = test_pd.apply(\n",
    "            lambda x: 1 if x['pred_bins'] != each and x['targ_bins'] == each else 0, axis=1).astype(float)\n",
    "        test_pd['fn'] += test_pd['fn_' + each]\n",
    "    \n",
    "    print(test_pd.head())\n",
    "    return test_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def early_stopping(net, epoch):\n",
    "    if epoch > net.minimum_epochs and net.loss_history[epoch-1] - net.loss_history[epoch] < net.required_delta:\n",
    "        net.failed_epochs += 1\n",
    "    else:\n",
    "        net.failed_epochs = 0\n",
    " \n",
    "    if net.failed_epochs > net.patience_epochs:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class FFDNN:\n",
    "    def __init__(self):\n",
    "        print('MODEL INIT')\n",
    "        tf.reset_default_graph()\n",
    "        self.krate = 0.5\n",
    "        self.batchtrain = False\n",
    "        self.loss_history = []\n",
    "        self.minimum_epochs = 100\n",
    "        self.required_delta = 0\n",
    "        self.failed_epochs = 0\n",
    "        self.patience_epochs = 10\n",
    "        self.epochs = 1000\n",
    "        self.input_shape = [None, train_xb[0].as_matrix().shape[1]]\n",
    "        self.output_shape = [None, train_yb[0].as_matrix().shape[1]]\n",
    "        self.inputs_ = tf.placeholder(tf.float32, shape=self.input_shape, name='inputs')\n",
    "        self.targets_ = tf.placeholder(tf.float32, shape=self.output_shape, name='targets')\n",
    "        self.train_learning_rate = 0.00025\n",
    "        self.lr_ = tf.placeholder(tf.float32, shape=[], name='lr')\n",
    "        self.training_ = tf.placeholder(tf.bool, shape=[], name='training')\n",
    "        self.logits = get_logits(self)\n",
    "        self.softmax = get_softmax(self.logits)\n",
    "        self.cost = get_cost(self.logits, self.targets_)\n",
    "        self.cross_entropy = write_cross_entropy(self.cost)\n",
    "        self.hypertune = set_hypertune_param(self.cost)\n",
    "        self.optimizer = get_optimizer(self.cost, self.lr_)\n",
    "        self.saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(net):\n",
    "    print('TRAIN')\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        ckpt = './activity6-v2.ckpt'\n",
    "        #net.saver.restore(sess, ckpt)\n",
    "        train_writer = tf.summary.FileWriter('logs/train', sess.graph)\n",
    "        eval_writer = tf.summary.FileWriter('logs/eval', sess.graph)\n",
    "        \n",
    "        iteration = 0\n",
    "        for e in range(net.epochs):\n",
    "            \n",
    "            if net.batchtrain == True:\n",
    "                for b_idx, b in enumerate(train_xb,0):\n",
    "                    iteration += 1\n",
    "                    x, y = train_xb[b_idx].as_matrix(), train_yb[b_idx].as_matrix()\n",
    "                    train_merged = tf.summary.merge([net.cross_entropy])\n",
    "\n",
    "                    # Train\n",
    "                    feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: True}\n",
    "                    summary_train, _, t_cost = sess.run([train_merged, net.optimizer, net.cost], feed_dict=feed)\n",
    "                    train_writer.add_summary(summary_train, iteration)\n",
    "            else:\n",
    "                iteration += 1\n",
    "                x, y = X_train.as_matrix(), y_train.as_matrix()\n",
    "                train_merged = tf.summary.merge([net.cross_entropy])\n",
    "\n",
    "                # Train\n",
    "                feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: True}\n",
    "                summary_train, _, t_cost = sess.run([train_merged, net.optimizer, net.cost], feed_dict=feed)\n",
    "                train_writer.add_summary(summary_train, iteration)\n",
    "            \n",
    "            x, y = X_eval.as_matrix(), y_eval.as_matrix()\n",
    "\n",
    "            feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: False}\n",
    "            summary_train_eval, cost = sess.run([train_merged, net.cost], feed_dict=feed)\n",
    "            net.loss_history.append(cost)\n",
    "            eval_writer.add_summary(summary_train_eval, iteration)\n",
    "            \n",
    "            print('Epoch ' + str(e) + ': Eval Loss = ' + str(cost) + ' Train Loss = ' + str(t_cost))\n",
    "            if(early_stopping(net, e)):\n",
    "                print(\"early stopping...\")\n",
    "                break\n",
    "\n",
    "        train_writer.close()\n",
    "        eval_writer.close()\n",
    "        net.saver.save(sess, './activity6-v2.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test(net):\n",
    "    print('TEST')\n",
    "    with tf.Session() as sess:\n",
    "        ckpt = './activity6-v2.ckpt'\n",
    "        net.saver.restore(sess, ckpt)\n",
    "            \n",
    "        x, y = X_test.as_matrix(), y_test.as_matrix()\n",
    "\n",
    "        feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: False}\n",
    "        pred = sess.run(net.softmax, feed_dict=feed)\n",
    "    \n",
    "    details_test = calculate_metrics(pred, y)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        net.saver.restore(sess, ckpt)\n",
    "        \n",
    "        x_all = pd.concat([X_train, X_test, X_eval], axis=0)\n",
    "        y_all = pd.concat([y_train, y_test, y_eval], axis=0)\n",
    "        x, y = x_all.as_matrix(), y_all.as_matrix()\n",
    "\n",
    "        feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: False}\n",
    "        pred = sess.run(net.softmax, feed_dict=feed)\n",
    "    \n",
    "    details_all = calculate_metrics(pred, y)\n",
    "    return details_test, details_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INIT\n",
      "WARNING:tensorflow:From /home/ubuntu/.virtualenvs/activity6/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-8-e56d12c6ce2f>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "TRAIN\n",
      "Epoch 0: Eval Loss = 1.6450273 Train Loss = 1.64987\n",
      "Epoch 1: Eval Loss = 1.6819569 Train Loss = 1.5600331\n",
      "Epoch 2: Eval Loss = 1.6691186 Train Loss = 1.5612855\n",
      "Epoch 3: Eval Loss = 1.6379749 Train Loss = 1.6295048\n",
      "Epoch 4: Eval Loss = 1.6081144 Train Loss = 1.5427324\n",
      "Epoch 5: Eval Loss = 1.5691789 Train Loss = 1.4938778\n",
      "Epoch 6: Eval Loss = 1.5236528 Train Loss = 1.64099\n",
      "Epoch 7: Eval Loss = 1.4764361 Train Loss = 1.4460144\n",
      "Epoch 8: Eval Loss = 1.4355156 Train Loss = 1.4652117\n",
      "Epoch 9: Eval Loss = 1.3984703 Train Loss = 1.4038742\n",
      "Epoch 10: Eval Loss = 1.369326 Train Loss = 1.5118448\n",
      "Epoch 11: Eval Loss = 1.3428175 Train Loss = 1.4400613\n",
      "Epoch 12: Eval Loss = 1.3119724 Train Loss = 1.5075799\n",
      "Epoch 13: Eval Loss = 1.2808883 Train Loss = 1.4372264\n",
      "Epoch 14: Eval Loss = 1.2517331 Train Loss = 1.4342402\n",
      "Epoch 15: Eval Loss = 1.2215321 Train Loss = 1.4533722\n",
      "Epoch 16: Eval Loss = 1.1942407 Train Loss = 1.4599048\n",
      "Epoch 17: Eval Loss = 1.169659 Train Loss = 1.3713372\n",
      "Epoch 18: Eval Loss = 1.1455543 Train Loss = 1.5119029\n",
      "Epoch 19: Eval Loss = 1.1258279 Train Loss = 1.4079027\n",
      "Epoch 20: Eval Loss = 1.1060616 Train Loss = 1.3219326\n",
      "Epoch 21: Eval Loss = 1.0882813 Train Loss = 1.3779693\n",
      "Epoch 22: Eval Loss = 1.0725886 Train Loss = 1.3054938\n",
      "Epoch 23: Eval Loss = 1.056935 Train Loss = 1.3319292\n",
      "Epoch 24: Eval Loss = 1.0428542 Train Loss = 1.3576028\n",
      "Epoch 25: Eval Loss = 1.0310276 Train Loss = 1.3130417\n",
      "Epoch 26: Eval Loss = 1.0201813 Train Loss = 1.3013214\n",
      "Epoch 27: Eval Loss = 1.0093061 Train Loss = 1.2534353\n",
      "Epoch 28: Eval Loss = 1.0001585 Train Loss = 1.2723118\n",
      "Epoch 29: Eval Loss = 0.99025077 Train Loss = 1.3425986\n",
      "Epoch 30: Eval Loss = 0.9814864 Train Loss = 1.2468468\n",
      "Epoch 31: Eval Loss = 0.9731216 Train Loss = 1.2434297\n",
      "Epoch 32: Eval Loss = 0.966099 Train Loss = 1.3654759\n",
      "Epoch 33: Eval Loss = 0.95906115 Train Loss = 1.2953084\n",
      "Epoch 34: Eval Loss = 0.9518642 Train Loss = 1.248399\n",
      "Epoch 35: Eval Loss = 0.94463587 Train Loss = 1.2252988\n",
      "Epoch 36: Eval Loss = 0.93864197 Train Loss = 1.3261431\n",
      "Epoch 37: Eval Loss = 0.93304133 Train Loss = 1.2658955\n",
      "Epoch 38: Eval Loss = 0.9288592 Train Loss = 1.2026161\n",
      "Epoch 39: Eval Loss = 0.9250478 Train Loss = 1.2326213\n",
      "Epoch 40: Eval Loss = 0.92196596 Train Loss = 1.2565782\n",
      "Epoch 41: Eval Loss = 0.9191632 Train Loss = 1.2521292\n",
      "Epoch 42: Eval Loss = 0.916277 Train Loss = 1.2815146\n",
      "Epoch 43: Eval Loss = 0.91333014 Train Loss = 1.151633\n",
      "Epoch 44: Eval Loss = 0.91083115 Train Loss = 1.2377857\n",
      "Epoch 45: Eval Loss = 0.9082642 Train Loss = 1.1697719\n",
      "Epoch 46: Eval Loss = 0.9060261 Train Loss = 1.1950415\n",
      "Epoch 47: Eval Loss = 0.9041949 Train Loss = 1.2370832\n",
      "Epoch 48: Eval Loss = 0.902282 Train Loss = 1.2211246\n",
      "Epoch 49: Eval Loss = 0.90057486 Train Loss = 1.2475305\n",
      "Epoch 50: Eval Loss = 0.8991659 Train Loss = 1.2249049\n",
      "Epoch 51: Eval Loss = 0.8979383 Train Loss = 1.1908886\n",
      "Epoch 52: Eval Loss = 0.89683205 Train Loss = 1.2057108\n",
      "Epoch 53: Eval Loss = 0.89608735 Train Loss = 1.2354321\n",
      "Epoch 54: Eval Loss = 0.89528066 Train Loss = 1.1956129\n",
      "Epoch 55: Eval Loss = 0.89446723 Train Loss = 1.2159065\n",
      "Epoch 56: Eval Loss = 0.8935811 Train Loss = 1.1526408\n",
      "Epoch 57: Eval Loss = 0.8925753 Train Loss = 1.2009404\n",
      "Epoch 58: Eval Loss = 0.8917658 Train Loss = 1.1865816\n",
      "Epoch 59: Eval Loss = 0.89076066 Train Loss = 1.1365495\n",
      "Epoch 60: Eval Loss = 0.89018553 Train Loss = 1.1227176\n",
      "Epoch 61: Eval Loss = 0.88992167 Train Loss = 1.1781205\n",
      "Epoch 62: Eval Loss = 0.88988775 Train Loss = 1.1396673\n",
      "Epoch 63: Eval Loss = 0.89002 Train Loss = 1.1857215\n",
      "Epoch 64: Eval Loss = 0.89048743 Train Loss = 1.1269952\n",
      "Epoch 65: Eval Loss = 0.89112955 Train Loss = 1.1054225\n",
      "Epoch 66: Eval Loss = 0.8921714 Train Loss = 1.1505599\n",
      "Epoch 67: Eval Loss = 0.8938185 Train Loss = 1.1677915\n",
      "Epoch 68: Eval Loss = 0.8954891 Train Loss = 1.1580428\n",
      "Epoch 69: Eval Loss = 0.8968818 Train Loss = 1.1466587\n",
      "Epoch 70: Eval Loss = 0.89805055 Train Loss = 1.1423583\n",
      "Epoch 71: Eval Loss = 0.89899683 Train Loss = 1.1087823\n",
      "Epoch 72: Eval Loss = 0.9004328 Train Loss = 1.1205543\n",
      "Epoch 73: Eval Loss = 0.9018554 Train Loss = 1.1181608\n",
      "Epoch 74: Eval Loss = 0.9035832 Train Loss = 1.1187174\n",
      "Epoch 75: Eval Loss = 0.90499425 Train Loss = 1.1265372\n",
      "Epoch 76: Eval Loss = 0.9065982 Train Loss = 1.0960169\n",
      "Epoch 77: Eval Loss = 0.90822875 Train Loss = 1.1376506\n",
      "Epoch 78: Eval Loss = 0.90967965 Train Loss = 1.0678123\n",
      "Epoch 79: Eval Loss = 0.91149527 Train Loss = 1.1687151\n",
      "Epoch 80: Eval Loss = 0.91295594 Train Loss = 1.1044332\n",
      "Epoch 81: Eval Loss = 0.9140928 Train Loss = 1.0852679\n",
      "Epoch 82: Eval Loss = 0.9154119 Train Loss = 1.0964863\n",
      "Epoch 83: Eval Loss = 0.9167044 Train Loss = 1.1049339\n",
      "Epoch 84: Eval Loss = 0.91795623 Train Loss = 1.080074\n",
      "Epoch 85: Eval Loss = 0.9187792 Train Loss = 1.106676\n",
      "Epoch 86: Eval Loss = 0.9192188 Train Loss = 1.0776892\n",
      "Epoch 87: Eval Loss = 0.9196707 Train Loss = 1.0764469\n",
      "Epoch 88: Eval Loss = 0.9200312 Train Loss = 1.025178\n",
      "Epoch 89: Eval Loss = 0.9204323 Train Loss = 1.1138313\n",
      "Epoch 90: Eval Loss = 0.9210715 Train Loss = 1.0686096\n",
      "Epoch 91: Eval Loss = 0.9218169 Train Loss = 1.1230515\n",
      "Epoch 92: Eval Loss = 0.92271143 Train Loss = 1.1361974\n",
      "Epoch 93: Eval Loss = 0.92342544 Train Loss = 1.1200213\n",
      "Epoch 94: Eval Loss = 0.9238072 Train Loss = 1.0254587\n",
      "Epoch 95: Eval Loss = 0.92383546 Train Loss = 1.0807605\n",
      "Epoch 96: Eval Loss = 0.9239103 Train Loss = 1.0653127\n",
      "Epoch 97: Eval Loss = 0.9237646 Train Loss = 1.0360798\n",
      "Epoch 98: Eval Loss = 0.9239221 Train Loss = 1.0838227\n",
      "Epoch 99: Eval Loss = 0.92393994 Train Loss = 1.075213\n",
      "Epoch 100: Eval Loss = 0.9238594 Train Loss = 1.0433229\n",
      "Epoch 101: Eval Loss = 0.923982 Train Loss = 1.0487062\n",
      "Epoch 102: Eval Loss = 0.92384154 Train Loss = 1.0471843\n",
      "Epoch 103: Eval Loss = 0.92378443 Train Loss = 1.0050048\n",
      "Epoch 104: Eval Loss = 0.9241693 Train Loss = 1.1036389\n",
      "Epoch 105: Eval Loss = 0.9240417 Train Loss = 0.99176997\n",
      "Epoch 106: Eval Loss = 0.92367905 Train Loss = 1.0228218\n",
      "Epoch 107: Eval Loss = 0.923503 Train Loss = 1.042544\n",
      "Epoch 108: Eval Loss = 0.9236685 Train Loss = 1.0540031\n",
      "Epoch 109: Eval Loss = 0.92368054 Train Loss = 1.0577809\n",
      "Epoch 110: Eval Loss = 0.9240529 Train Loss = 1.0180823\n",
      "Epoch 111: Eval Loss = 0.924349 Train Loss = 1.0659636\n",
      "Epoch 112: Eval Loss = 0.92452806 Train Loss = 1.0821135\n",
      "Epoch 113: Eval Loss = 0.9246055 Train Loss = 1.0758685\n",
      "Epoch 114: Eval Loss = 0.92468965 Train Loss = 1.027158\n",
      "Epoch 115: Eval Loss = 0.9245194 Train Loss = 1.016961\n",
      "Epoch 116: Eval Loss = 0.9244028 Train Loss = 1.0444019\n",
      "Epoch 117: Eval Loss = 0.9242561 Train Loss = 1.0964595\n",
      "Epoch 118: Eval Loss = 0.9242112 Train Loss = 0.98385954\n",
      "Epoch 119: Eval Loss = 0.9240731 Train Loss = 1.0478721\n",
      "Epoch 120: Eval Loss = 0.92380065 Train Loss = 1.0174153\n",
      "Epoch 121: Eval Loss = 0.92336035 Train Loss = 1.0119336\n",
      "Epoch 122: Eval Loss = 0.92304593 Train Loss = 1.0460209\n",
      "Epoch 123: Eval Loss = 0.92246515 Train Loss = 1.0221499\n",
      "Epoch 124: Eval Loss = 0.9220096 Train Loss = 1.0075257\n",
      "Epoch 125: Eval Loss = 0.9211718 Train Loss = 1.1023442\n",
      "Epoch 126: Eval Loss = 0.9205674 Train Loss = 1.0829484\n",
      "Epoch 127: Eval Loss = 0.9198015 Train Loss = 1.0029359\n",
      "Epoch 128: Eval Loss = 0.91897273 Train Loss = 0.9969983\n",
      "Epoch 129: Eval Loss = 0.91783226 Train Loss = 1.0285733\n",
      "Epoch 130: Eval Loss = 0.9169319 Train Loss = 1.000665\n",
      "Epoch 131: Eval Loss = 0.91599005 Train Loss = 1.0219429\n",
      "Epoch 132: Eval Loss = 0.91520685 Train Loss = 1.0163546\n",
      "Epoch 133: Eval Loss = 0.91435784 Train Loss = 1.0507146\n",
      "Epoch 134: Eval Loss = 0.91401994 Train Loss = 1.0317905\n",
      "Epoch 135: Eval Loss = 0.9134552 Train Loss = 0.9950935\n",
      "Epoch 136: Eval Loss = 0.9128661 Train Loss = 0.9730192\n",
      "Epoch 137: Eval Loss = 0.91209894 Train Loss = 1.0731597\n",
      "Epoch 138: Eval Loss = 0.9112464 Train Loss = 0.9992603\n",
      "Epoch 139: Eval Loss = 0.91040933 Train Loss = 1.0153127\n",
      "Epoch 140: Eval Loss = 0.9097564 Train Loss = 1.0093182\n",
      "Epoch 141: Eval Loss = 0.9087975 Train Loss = 1.0099267\n",
      "Epoch 142: Eval Loss = 0.9081233 Train Loss = 0.98783445\n",
      "Epoch 143: Eval Loss = 0.90743315 Train Loss = 0.98541933\n",
      "Epoch 144: Eval Loss = 0.9068532 Train Loss = 0.99407417\n",
      "Epoch 145: Eval Loss = 0.9061941 Train Loss = 0.9847363\n",
      "Epoch 146: Eval Loss = 0.90559006 Train Loss = 0.9466438\n",
      "Epoch 147: Eval Loss = 0.90511703 Train Loss = 0.9886889\n",
      "Epoch 148: Eval Loss = 0.90454835 Train Loss = 1.0593386\n",
      "Epoch 149: Eval Loss = 0.90405226 Train Loss = 0.97141623\n",
      "Epoch 150: Eval Loss = 0.9034454 Train Loss = 0.99793625\n",
      "Epoch 151: Eval Loss = 0.902941 Train Loss = 0.9935673\n",
      "Epoch 152: Eval Loss = 0.9023091 Train Loss = 0.99947524\n",
      "Epoch 153: Eval Loss = 0.90196234 Train Loss = 0.98319983\n",
      "Epoch 154: Eval Loss = 0.9014151 Train Loss = 1.0282125\n",
      "Epoch 155: Eval Loss = 0.9008243 Train Loss = 0.9777755\n",
      "Epoch 156: Eval Loss = 0.90025383 Train Loss = 0.9946562\n",
      "Epoch 157: Eval Loss = 0.89968514 Train Loss = 0.9794036\n",
      "Epoch 158: Eval Loss = 0.89908874 Train Loss = 1.0145799\n",
      "Epoch 159: Eval Loss = 0.89837724 Train Loss = 1.0274507\n",
      "Epoch 160: Eval Loss = 0.8976922 Train Loss = 0.95770943\n",
      "Epoch 161: Eval Loss = 0.89696413 Train Loss = 0.9625285\n",
      "Epoch 162: Eval Loss = 0.89642143 Train Loss = 0.95915556\n",
      "Epoch 163: Eval Loss = 0.89575857 Train Loss = 0.96668607\n",
      "Epoch 164: Eval Loss = 0.89526045 Train Loss = 0.9083994\n",
      "Epoch 165: Eval Loss = 0.89499605 Train Loss = 0.97847795\n",
      "Epoch 166: Eval Loss = 0.8943336 Train Loss = 1.0125096\n",
      "Epoch 167: Eval Loss = 0.8938424 Train Loss = 0.97478867\n",
      "Epoch 168: Eval Loss = 0.89360285 Train Loss = 0.9533264\n",
      "Epoch 169: Eval Loss = 0.89338684 Train Loss = 1.0013729\n",
      "Epoch 170: Eval Loss = 0.89305776 Train Loss = 1.0048149\n",
      "Epoch 171: Eval Loss = 0.89273477 Train Loss = 0.9930327\n",
      "Epoch 172: Eval Loss = 0.8924343 Train Loss = 0.9791829\n",
      "Epoch 173: Eval Loss = 0.8923157 Train Loss = 1.0078219\n",
      "Epoch 174: Eval Loss = 0.8920716 Train Loss = 1.0249383\n",
      "Epoch 175: Eval Loss = 0.89181495 Train Loss = 0.9865033\n",
      "Epoch 176: Eval Loss = 0.89168143 Train Loss = 0.9435511\n",
      "Epoch 177: Eval Loss = 0.89138675 Train Loss = 0.9721143\n",
      "Epoch 178: Eval Loss = 0.8912258 Train Loss = 0.9934623\n",
      "Epoch 179: Eval Loss = 0.89098716 Train Loss = 0.94773096\n",
      "Epoch 180: Eval Loss = 0.89054316 Train Loss = 0.9803894\n",
      "Epoch 181: Eval Loss = 0.89007396 Train Loss = 0.9828976\n",
      "Epoch 182: Eval Loss = 0.88952947 Train Loss = 0.98179656\n",
      "Epoch 183: Eval Loss = 0.88868845 Train Loss = 0.97873586\n",
      "Epoch 184: Eval Loss = 0.8879993 Train Loss = 0.93948853\n",
      "Epoch 185: Eval Loss = 0.8872549 Train Loss = 1.0076001\n",
      "Epoch 186: Eval Loss = 0.88656294 Train Loss = 0.9616626\n",
      "Epoch 187: Eval Loss = 0.8859894 Train Loss = 0.9650978\n",
      "Epoch 188: Eval Loss = 0.88537484 Train Loss = 0.9435117\n",
      "Epoch 189: Eval Loss = 0.8846541 Train Loss = 0.94834036\n",
      "Epoch 190: Eval Loss = 0.8838133 Train Loss = 0.9659687\n",
      "Epoch 191: Eval Loss = 0.8831549 Train Loss = 0.9144379\n",
      "Epoch 192: Eval Loss = 0.8823504 Train Loss = 0.99341714\n",
      "Epoch 193: Eval Loss = 0.88161933 Train Loss = 0.97797894\n",
      "Epoch 194: Eval Loss = 0.8808589 Train Loss = 1.0113488\n",
      "Epoch 195: Eval Loss = 0.8802208 Train Loss = 0.97941023\n",
      "Epoch 196: Eval Loss = 0.879719 Train Loss = 0.9728073\n",
      "Epoch 197: Eval Loss = 0.8791711 Train Loss = 0.96890825\n",
      "Epoch 198: Eval Loss = 0.87862307 Train Loss = 0.9277285\n",
      "Epoch 199: Eval Loss = 0.87785864 Train Loss = 0.9237999\n",
      "Epoch 200: Eval Loss = 0.8771251 Train Loss = 0.9640582\n",
      "Epoch 201: Eval Loss = 0.8763133 Train Loss = 0.91696495\n",
      "Epoch 202: Eval Loss = 0.8756206 Train Loss = 0.973705\n",
      "Epoch 203: Eval Loss = 0.87506104 Train Loss = 0.9481668\n",
      "Epoch 204: Eval Loss = 0.8744795 Train Loss = 1.0040556\n",
      "Epoch 205: Eval Loss = 0.8738295 Train Loss = 0.96037066\n",
      "Epoch 206: Eval Loss = 0.8731013 Train Loss = 0.96961755\n",
      "Epoch 207: Eval Loss = 0.87246084 Train Loss = 0.95006037\n",
      "Epoch 208: Eval Loss = 0.8718082 Train Loss = 0.95268774\n",
      "Epoch 209: Eval Loss = 0.87107 Train Loss = 0.96811223\n",
      "Epoch 210: Eval Loss = 0.8703471 Train Loss = 0.94799256\n",
      "Epoch 211: Eval Loss = 0.8697548 Train Loss = 0.9709575\n",
      "Epoch 212: Eval Loss = 0.8692337 Train Loss = 0.973199\n",
      "Epoch 213: Eval Loss = 0.868867 Train Loss = 1.0123236\n",
      "Epoch 214: Eval Loss = 0.8682681 Train Loss = 0.96524024\n",
      "Epoch 215: Eval Loss = 0.86782324 Train Loss = 0.9452284\n",
      "Epoch 216: Eval Loss = 0.8672896 Train Loss = 1.0156614\n",
      "Epoch 217: Eval Loss = 0.8666866 Train Loss = 0.95206726\n",
      "Epoch 218: Eval Loss = 0.8660044 Train Loss = 0.95833826\n",
      "Epoch 219: Eval Loss = 0.86532706 Train Loss = 0.95158964\n",
      "Epoch 220: Eval Loss = 0.8646441 Train Loss = 0.92666054\n",
      "Epoch 221: Eval Loss = 0.86383784 Train Loss = 0.9746254\n",
      "Epoch 222: Eval Loss = 0.8630913 Train Loss = 0.9683915\n",
      "Epoch 223: Eval Loss = 0.86232966 Train Loss = 0.9297178\n",
      "Epoch 224: Eval Loss = 0.8615834 Train Loss = 0.9092773\n",
      "Epoch 225: Eval Loss = 0.8607325 Train Loss = 0.94684374\n",
      "Epoch 226: Eval Loss = 0.8596393 Train Loss = 0.933002\n",
      "Epoch 227: Eval Loss = 0.85875356 Train Loss = 0.9391311\n",
      "Epoch 228: Eval Loss = 0.85768074 Train Loss = 0.9516853\n",
      "Epoch 229: Eval Loss = 0.85674345 Train Loss = 0.9490038\n",
      "Epoch 230: Eval Loss = 0.85570884 Train Loss = 0.9760102\n",
      "Epoch 231: Eval Loss = 0.8546724 Train Loss = 0.9494639\n",
      "Epoch 232: Eval Loss = 0.8536631 Train Loss = 0.9140497\n",
      "Epoch 233: Eval Loss = 0.85260886 Train Loss = 0.940861\n",
      "Epoch 234: Eval Loss = 0.85140014 Train Loss = 0.9114219\n",
      "Epoch 235: Eval Loss = 0.8503006 Train Loss = 0.96718925\n",
      "Epoch 236: Eval Loss = 0.8493677 Train Loss = 0.9297696\n",
      "Epoch 237: Eval Loss = 0.8484876 Train Loss = 0.89185256\n",
      "Epoch 238: Eval Loss = 0.84749216 Train Loss = 0.93672293\n",
      "Epoch 239: Eval Loss = 0.8464674 Train Loss = 0.9852658\n",
      "Epoch 240: Eval Loss = 0.8454836 Train Loss = 0.93280756\n",
      "Epoch 241: Eval Loss = 0.84469163 Train Loss = 0.90693307\n",
      "Epoch 242: Eval Loss = 0.84381884 Train Loss = 0.94045585\n",
      "Epoch 243: Eval Loss = 0.8428211 Train Loss = 0.954453\n",
      "Epoch 244: Eval Loss = 0.84185046 Train Loss = 0.91177505\n",
      "Epoch 245: Eval Loss = 0.8408658 Train Loss = 0.92682207\n",
      "Epoch 246: Eval Loss = 0.8397843 Train Loss = 0.93634707\n",
      "Epoch 247: Eval Loss = 0.83872485 Train Loss = 0.9783751\n",
      "Epoch 248: Eval Loss = 0.83777183 Train Loss = 0.8754892\n",
      "Epoch 249: Eval Loss = 0.8369028 Train Loss = 0.90425354\n",
      "Epoch 250: Eval Loss = 0.8360699 Train Loss = 0.91927904\n",
      "Epoch 251: Eval Loss = 0.8350487 Train Loss = 0.94063914\n",
      "Epoch 252: Eval Loss = 0.8341879 Train Loss = 0.9252556\n",
      "Epoch 253: Eval Loss = 0.83329797 Train Loss = 0.89671946\n",
      "Epoch 254: Eval Loss = 0.8325073 Train Loss = 0.9357882\n",
      "Epoch 255: Eval Loss = 0.8315742 Train Loss = 0.90044665\n",
      "Epoch 256: Eval Loss = 0.8307097 Train Loss = 0.8768496\n",
      "Epoch 257: Eval Loss = 0.8299115 Train Loss = 0.9497928\n",
      "Epoch 258: Eval Loss = 0.8291699 Train Loss = 0.9248304\n",
      "Epoch 259: Eval Loss = 0.82847184 Train Loss = 0.9132202\n",
      "Epoch 260: Eval Loss = 0.8278108 Train Loss = 0.9099402\n",
      "Epoch 261: Eval Loss = 0.82712346 Train Loss = 0.9161525\n",
      "Epoch 262: Eval Loss = 0.8263899 Train Loss = 0.9433447\n",
      "Epoch 263: Eval Loss = 0.82574344 Train Loss = 0.9221756\n",
      "Epoch 264: Eval Loss = 0.82515526 Train Loss = 0.95333344\n",
      "Epoch 265: Eval Loss = 0.82468283 Train Loss = 0.9370634\n",
      "Epoch 266: Eval Loss = 0.8242453 Train Loss = 0.9216285\n",
      "Epoch 267: Eval Loss = 0.8236408 Train Loss = 0.9231562\n",
      "Epoch 268: Eval Loss = 0.82306784 Train Loss = 0.93031865\n",
      "Epoch 269: Eval Loss = 0.822704 Train Loss = 0.9103235\n",
      "Epoch 270: Eval Loss = 0.8220896 Train Loss = 0.9051653\n",
      "Epoch 271: Eval Loss = 0.8215751 Train Loss = 0.8845891\n",
      "Epoch 272: Eval Loss = 0.82101226 Train Loss = 0.8987711\n",
      "Epoch 273: Eval Loss = 0.8204947 Train Loss = 0.9356084\n",
      "Epoch 274: Eval Loss = 0.8199171 Train Loss = 0.925966\n",
      "Epoch 275: Eval Loss = 0.81946635 Train Loss = 0.9175721\n",
      "Epoch 276: Eval Loss = 0.8189338 Train Loss = 0.9250667\n",
      "Epoch 277: Eval Loss = 0.81842774 Train Loss = 0.8813217\n",
      "Epoch 278: Eval Loss = 0.8177688 Train Loss = 0.94910586\n",
      "Epoch 279: Eval Loss = 0.8170562 Train Loss = 0.91667086\n",
      "Epoch 280: Eval Loss = 0.81650627 Train Loss = 0.90006083\n",
      "Epoch 281: Eval Loss = 0.8159049 Train Loss = 0.89664274\n",
      "Epoch 282: Eval Loss = 0.8151406 Train Loss = 0.8900571\n",
      "Epoch 283: Eval Loss = 0.814452 Train Loss = 0.85432535\n",
      "Epoch 284: Eval Loss = 0.8138619 Train Loss = 0.9343518\n",
      "Epoch 285: Eval Loss = 0.8132708 Train Loss = 0.9297878\n",
      "Epoch 286: Eval Loss = 0.8127749 Train Loss = 0.9671273\n",
      "Epoch 287: Eval Loss = 0.8122509 Train Loss = 0.8648199\n",
      "Epoch 288: Eval Loss = 0.81178766 Train Loss = 0.9168478\n",
      "Epoch 289: Eval Loss = 0.8113641 Train Loss = 0.91395307\n",
      "Epoch 290: Eval Loss = 0.8109825 Train Loss = 0.9020234\n",
      "Epoch 291: Eval Loss = 0.8106927 Train Loss = 0.85689497\n",
      "Epoch 292: Eval Loss = 0.81050104 Train Loss = 0.860659\n",
      "Epoch 293: Eval Loss = 0.8103343 Train Loss = 0.9028591\n",
      "Epoch 294: Eval Loss = 0.81017596 Train Loss = 0.8927577\n",
      "Epoch 295: Eval Loss = 0.8098861 Train Loss = 0.91872567\n",
      "Epoch 296: Eval Loss = 0.8097205 Train Loss = 0.9148486\n",
      "Epoch 297: Eval Loss = 0.80965114 Train Loss = 0.93683887\n",
      "Epoch 298: Eval Loss = 0.8093483 Train Loss = 0.9216591\n",
      "Epoch 299: Eval Loss = 0.8090474 Train Loss = 0.93934476\n",
      "Epoch 300: Eval Loss = 0.80888176 Train Loss = 0.84965515\n",
      "Epoch 301: Eval Loss = 0.8086346 Train Loss = 0.90600795\n",
      "Epoch 302: Eval Loss = 0.8084566 Train Loss = 0.9389202\n",
      "Epoch 303: Eval Loss = 0.80828094 Train Loss = 0.8998081\n",
      "Epoch 304: Eval Loss = 0.80803037 Train Loss = 0.878643\n",
      "Epoch 305: Eval Loss = 0.80779594 Train Loss = 0.8891628\n",
      "Epoch 306: Eval Loss = 0.80772614 Train Loss = 0.9117319\n",
      "Epoch 307: Eval Loss = 0.8073638 Train Loss = 0.8786522\n",
      "Epoch 308: Eval Loss = 0.80718505 Train Loss = 0.9008908\n",
      "Epoch 309: Eval Loss = 0.80695224 Train Loss = 0.86133695\n",
      "Epoch 310: Eval Loss = 0.806652 Train Loss = 0.9226538\n",
      "Epoch 311: Eval Loss = 0.8062948 Train Loss = 0.8947889\n",
      "Epoch 312: Eval Loss = 0.8060393 Train Loss = 0.84952843\n",
      "Epoch 313: Eval Loss = 0.80568606 Train Loss = 0.95003146\n",
      "Epoch 314: Eval Loss = 0.8053927 Train Loss = 0.8599605\n",
      "Epoch 315: Eval Loss = 0.8050706 Train Loss = 0.92483574\n",
      "Epoch 316: Eval Loss = 0.8047825 Train Loss = 0.93060595\n",
      "Epoch 317: Eval Loss = 0.8045391 Train Loss = 0.91475844\n",
      "Epoch 318: Eval Loss = 0.80438197 Train Loss = 0.9094155\n",
      "Epoch 319: Eval Loss = 0.8042268 Train Loss = 0.8693073\n",
      "Epoch 320: Eval Loss = 0.80407697 Train Loss = 0.88682276\n",
      "Epoch 321: Eval Loss = 0.80404824 Train Loss = 0.937078\n",
      "Epoch 322: Eval Loss = 0.8038864 Train Loss = 0.89438325\n",
      "Epoch 323: Eval Loss = 0.8036957 Train Loss = 0.9004933\n",
      "Epoch 324: Eval Loss = 0.803391 Train Loss = 0.892876\n",
      "Epoch 325: Eval Loss = 0.80317223 Train Loss = 0.9221262\n",
      "Epoch 326: Eval Loss = 0.8028669 Train Loss = 0.88929445\n",
      "Epoch 327: Eval Loss = 0.8026254 Train Loss = 0.9027717\n",
      "Epoch 328: Eval Loss = 0.80243003 Train Loss = 0.9019758\n",
      "Epoch 329: Eval Loss = 0.8022839 Train Loss = 0.86968756\n",
      "Epoch 330: Eval Loss = 0.8020568 Train Loss = 0.8707199\n",
      "Epoch 331: Eval Loss = 0.8017273 Train Loss = 0.88031656\n",
      "Epoch 332: Eval Loss = 0.8013725 Train Loss = 0.92564774\n",
      "Epoch 333: Eval Loss = 0.801029 Train Loss = 0.9356803\n",
      "Epoch 334: Eval Loss = 0.8006643 Train Loss = 0.9049642\n",
      "Epoch 335: Eval Loss = 0.80040765 Train Loss = 0.8881529\n",
      "Epoch 336: Eval Loss = 0.8000158 Train Loss = 0.8878267\n",
      "Epoch 337: Eval Loss = 0.79979384 Train Loss = 0.8474315\n",
      "Epoch 338: Eval Loss = 0.7996008 Train Loss = 0.89801115\n",
      "Epoch 339: Eval Loss = 0.7992608 Train Loss = 0.87385255\n",
      "Epoch 340: Eval Loss = 0.7990544 Train Loss = 0.909301\n",
      "Epoch 341: Eval Loss = 0.79861975 Train Loss = 0.86519766\n",
      "Epoch 342: Eval Loss = 0.7982125 Train Loss = 0.9236335\n",
      "Epoch 343: Eval Loss = 0.79785377 Train Loss = 0.86133677\n",
      "Epoch 344: Eval Loss = 0.7974072 Train Loss = 0.85774064\n",
      "Epoch 345: Eval Loss = 0.7970631 Train Loss = 0.85286605\n",
      "Epoch 346: Eval Loss = 0.7967423 Train Loss = 0.88971555\n",
      "Epoch 347: Eval Loss = 0.79640394 Train Loss = 0.91483855\n",
      "Epoch 348: Eval Loss = 0.79610497 Train Loss = 0.8514211\n",
      "Epoch 349: Eval Loss = 0.7958143 Train Loss = 0.86756223\n",
      "Epoch 350: Eval Loss = 0.79553485 Train Loss = 0.882825\n",
      "Epoch 351: Eval Loss = 0.79527783 Train Loss = 0.8812551\n",
      "Epoch 352: Eval Loss = 0.7950899 Train Loss = 0.86236495\n",
      "Epoch 353: Eval Loss = 0.7949938 Train Loss = 0.8576522\n",
      "Epoch 354: Eval Loss = 0.79482466 Train Loss = 0.86242384\n",
      "Epoch 355: Eval Loss = 0.7946993 Train Loss = 0.8307332\n",
      "Epoch 356: Eval Loss = 0.79446757 Train Loss = 0.9498201\n",
      "Epoch 357: Eval Loss = 0.79418963 Train Loss = 0.8865094\n",
      "Epoch 358: Eval Loss = 0.7937897 Train Loss = 0.8459818\n",
      "Epoch 359: Eval Loss = 0.79346067 Train Loss = 0.83699054\n",
      "Epoch 360: Eval Loss = 0.79321826 Train Loss = 0.87106603\n",
      "Epoch 361: Eval Loss = 0.79304105 Train Loss = 0.8815718\n",
      "Epoch 362: Eval Loss = 0.7928848 Train Loss = 0.8336393\n",
      "Epoch 363: Eval Loss = 0.79285043 Train Loss = 0.88203424\n",
      "Epoch 364: Eval Loss = 0.79278594 Train Loss = 0.83276474\n",
      "Epoch 365: Eval Loss = 0.7927107 Train Loss = 0.90426517\n",
      "Epoch 366: Eval Loss = 0.79255205 Train Loss = 0.8791567\n",
      "Epoch 367: Eval Loss = 0.7923414 Train Loss = 0.8823068\n",
      "Epoch 368: Eval Loss = 0.79211587 Train Loss = 0.86022073\n",
      "Epoch 369: Eval Loss = 0.7919123 Train Loss = 0.85642487\n",
      "Epoch 370: Eval Loss = 0.79169214 Train Loss = 0.8171744\n",
      "Epoch 371: Eval Loss = 0.7914562 Train Loss = 0.86043304\n",
      "Epoch 372: Eval Loss = 0.7912172 Train Loss = 0.8607681\n",
      "Epoch 373: Eval Loss = 0.7909685 Train Loss = 0.87772197\n",
      "Epoch 374: Eval Loss = 0.7905653 Train Loss = 0.8489307\n",
      "Epoch 375: Eval Loss = 0.7902767 Train Loss = 0.8232172\n",
      "Epoch 376: Eval Loss = 0.789892 Train Loss = 0.8790212\n",
      "Epoch 377: Eval Loss = 0.78958786 Train Loss = 0.91389275\n",
      "Epoch 378: Eval Loss = 0.7892932 Train Loss = 0.8561543\n",
      "Epoch 379: Eval Loss = 0.78907317 Train Loss = 0.823954\n",
      "Epoch 380: Eval Loss = 0.78891844 Train Loss = 0.88279563\n",
      "Epoch 381: Eval Loss = 0.7886107 Train Loss = 0.90146726\n",
      "Epoch 382: Eval Loss = 0.78845143 Train Loss = 0.8667152\n",
      "Epoch 383: Eval Loss = 0.7882543 Train Loss = 0.84093237\n",
      "Epoch 384: Eval Loss = 0.78803235 Train Loss = 0.8741238\n",
      "Epoch 385: Eval Loss = 0.7878408 Train Loss = 0.8963959\n",
      "Epoch 386: Eval Loss = 0.78769654 Train Loss = 0.9049495\n",
      "Epoch 387: Eval Loss = 0.78751594 Train Loss = 0.8609052\n",
      "Epoch 388: Eval Loss = 0.78740525 Train Loss = 0.8605382\n",
      "Epoch 389: Eval Loss = 0.78732675 Train Loss = 0.83265823\n",
      "Epoch 390: Eval Loss = 0.78718 Train Loss = 0.8468973\n",
      "Epoch 391: Eval Loss = 0.7869739 Train Loss = 0.893374\n",
      "Epoch 392: Eval Loss = 0.78683823 Train Loss = 0.85504967\n",
      "Epoch 393: Eval Loss = 0.78669745 Train Loss = 0.8648087\n",
      "Epoch 394: Eval Loss = 0.78670716 Train Loss = 0.86444056\n",
      "Epoch 395: Eval Loss = 0.78666687 Train Loss = 0.87557864\n",
      "Epoch 396: Eval Loss = 0.78641707 Train Loss = 0.83572084\n",
      "Epoch 397: Eval Loss = 0.7863114 Train Loss = 0.8130179\n",
      "Epoch 398: Eval Loss = 0.7861566 Train Loss = 0.8264702\n",
      "Epoch 399: Eval Loss = 0.78603816 Train Loss = 0.8601842\n",
      "Epoch 400: Eval Loss = 0.7859086 Train Loss = 0.8797107\n",
      "Epoch 401: Eval Loss = 0.78581315 Train Loss = 0.8469789\n",
      "Epoch 402: Eval Loss = 0.7856914 Train Loss = 0.85845166\n",
      "Epoch 403: Eval Loss = 0.7855544 Train Loss = 0.86511755\n",
      "Epoch 404: Eval Loss = 0.785445 Train Loss = 0.9065974\n",
      "Epoch 405: Eval Loss = 0.78536576 Train Loss = 0.828911\n",
      "Epoch 406: Eval Loss = 0.7852953 Train Loss = 0.8627524\n",
      "Epoch 407: Eval Loss = 0.7850859 Train Loss = 0.8574794\n",
      "Epoch 408: Eval Loss = 0.78514266 Train Loss = 0.84447336\n",
      "Epoch 409: Eval Loss = 0.7851439 Train Loss = 0.83059084\n",
      "Epoch 410: Eval Loss = 0.78508836 Train Loss = 0.8598555\n",
      "Epoch 411: Eval Loss = 0.7850187 Train Loss = 0.8270563\n",
      "Epoch 412: Eval Loss = 0.7849194 Train Loss = 0.8109217\n",
      "Epoch 413: Eval Loss = 0.7848631 Train Loss = 0.82477105\n",
      "Epoch 414: Eval Loss = 0.7848274 Train Loss = 0.87193495\n",
      "Epoch 415: Eval Loss = 0.7847224 Train Loss = 0.8299822\n",
      "Epoch 416: Eval Loss = 0.7846627 Train Loss = 0.8336492\n",
      "Epoch 417: Eval Loss = 0.7845557 Train Loss = 0.8381588\n",
      "Epoch 418: Eval Loss = 0.78433955 Train Loss = 0.8292496\n",
      "Epoch 419: Eval Loss = 0.78436476 Train Loss = 0.86006606\n",
      "Epoch 420: Eval Loss = 0.7842239 Train Loss = 0.90112025\n",
      "Epoch 421: Eval Loss = 0.7842913 Train Loss = 0.8470105\n",
      "Epoch 422: Eval Loss = 0.78433055 Train Loss = 0.8582951\n",
      "Epoch 423: Eval Loss = 0.7844312 Train Loss = 0.8106871\n",
      "Epoch 424: Eval Loss = 0.78450334 Train Loss = 0.8372783\n",
      "Epoch 425: Eval Loss = 0.7844889 Train Loss = 0.8397056\n",
      "Epoch 426: Eval Loss = 0.78444046 Train Loss = 0.8516269\n",
      "Epoch 427: Eval Loss = 0.78447324 Train Loss = 0.81657296\n",
      "Epoch 428: Eval Loss = 0.78453755 Train Loss = 0.8732092\n",
      "Epoch 429: Eval Loss = 0.7844898 Train Loss = 0.81711304\n",
      "Epoch 430: Eval Loss = 0.78447145 Train Loss = 0.898459\n",
      "Epoch 431: Eval Loss = 0.7843961 Train Loss = 0.8626537\n",
      "Epoch 432: Eval Loss = 0.7843644 Train Loss = 0.8489604\n",
      "Epoch 433: Eval Loss = 0.7844034 Train Loss = 0.79554003\n",
      "Epoch 434: Eval Loss = 0.7844626 Train Loss = 0.83456933\n",
      "Epoch 435: Eval Loss = 0.7844559 Train Loss = 0.8581881\n",
      "Epoch 436: Eval Loss = 0.7844937 Train Loss = 0.84701437\n",
      "Epoch 437: Eval Loss = 0.78438425 Train Loss = 0.82508093\n",
      "Epoch 438: Eval Loss = 0.7842873 Train Loss = 0.84565765\n",
      "Epoch 439: Eval Loss = 0.7841628 Train Loss = 0.822632\n",
      "Epoch 440: Eval Loss = 0.7840525 Train Loss = 0.8427742\n",
      "Epoch 441: Eval Loss = 0.7838675 Train Loss = 0.83374524\n",
      "Epoch 442: Eval Loss = 0.7837179 Train Loss = 0.8141964\n",
      "Epoch 443: Eval Loss = 0.7834084 Train Loss = 0.8572773\n",
      "Epoch 444: Eval Loss = 0.7831753 Train Loss = 0.7935167\n",
      "Epoch 445: Eval Loss = 0.7829446 Train Loss = 0.83237284\n",
      "Epoch 446: Eval Loss = 0.7827876 Train Loss = 0.8413077\n",
      "Epoch 447: Eval Loss = 0.7826441 Train Loss = 0.8045444\n",
      "Epoch 448: Eval Loss = 0.7824707 Train Loss = 0.81723374\n",
      "Epoch 449: Eval Loss = 0.78229064 Train Loss = 0.85917056\n",
      "Epoch 450: Eval Loss = 0.78219396 Train Loss = 0.78457177\n",
      "Epoch 451: Eval Loss = 0.7820835 Train Loss = 0.81970084\n",
      "Epoch 452: Eval Loss = 0.7820497 Train Loss = 0.84089875\n",
      "Epoch 453: Eval Loss = 0.7819655 Train Loss = 0.8435982\n",
      "Epoch 454: Eval Loss = 0.78192216 Train Loss = 0.8047171\n",
      "Epoch 455: Eval Loss = 0.7818966 Train Loss = 0.80960083\n",
      "Epoch 456: Eval Loss = 0.7819214 Train Loss = 0.8199593\n",
      "Epoch 457: Eval Loss = 0.7818971 Train Loss = 0.81279045\n",
      "Epoch 458: Eval Loss = 0.7819582 Train Loss = 0.82279176\n",
      "Epoch 459: Eval Loss = 0.78198683 Train Loss = 0.8319247\n",
      "Epoch 460: Eval Loss = 0.782072 Train Loss = 0.85800844\n",
      "Epoch 461: Eval Loss = 0.7821217 Train Loss = 0.85750467\n",
      "Epoch 462: Eval Loss = 0.7821593 Train Loss = 0.83229125\n",
      "Epoch 463: Eval Loss = 0.7823436 Train Loss = 0.82357615\n",
      "Epoch 464: Eval Loss = 0.7824145 Train Loss = 0.79877305\n",
      "Epoch 465: Eval Loss = 0.78250635 Train Loss = 0.84010834\n",
      "Epoch 466: Eval Loss = 0.78252083 Train Loss = 0.8756278\n",
      "Epoch 467: Eval Loss = 0.78248024 Train Loss = 0.8249542\n",
      "Epoch 468: Eval Loss = 0.7824855 Train Loss = 0.79608136\n",
      "Epoch 469: Eval Loss = 0.782502 Train Loss = 0.83902586\n",
      "Epoch 470: Eval Loss = 0.7825272 Train Loss = 0.8536904\n",
      "Epoch 471: Eval Loss = 0.78258157 Train Loss = 0.83678335\n",
      "Epoch 472: Eval Loss = 0.78271466 Train Loss = 0.8317463\n",
      "Epoch 473: Eval Loss = 0.7828012 Train Loss = 0.8447677\n",
      "Epoch 474: Eval Loss = 0.78293043 Train Loss = 0.8530205\n",
      "Epoch 475: Eval Loss = 0.78307587 Train Loss = 0.83618134\n",
      "Epoch 476: Eval Loss = 0.7831939 Train Loss = 0.8504068\n",
      "Epoch 477: Eval Loss = 0.7833603 Train Loss = 0.76348174\n",
      "Epoch 478: Eval Loss = 0.78346324 Train Loss = 0.8041046\n",
      "early stopping...\n"
     ]
    }
   ],
   "source": [
    "net = FFDNN()\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "INFO:tensorflow:Restoring parameters from ./activity6-v2.ckpt\n",
      "        YES       OBS        NO pred_bins  YES  OBS  NO targ_bins   tp   fp  \\\n",
      "0  0.793526  0.157238  0.049236       YES    1    0   0       YES  1.0  0.0   \n",
      "1  0.563311  0.363897  0.072793       YES    1    0   0       YES  1.0  0.0   \n",
      "2  0.581209  0.306156  0.112635       YES    1    0   0       YES  1.0  0.0   \n",
      "3  0.692008  0.169909  0.138083       YES    0    0   1        NO  0.0  1.0   \n",
      "4  0.728304  0.143228  0.128468       YES    1    0   0       YES  1.0  0.0   \n",
      "\n",
      "    fn  tp_YES  fp_YES  fn_YES  tp_OBS  fp_OBS  fn_OBS  tp_NO  fp_NO  fn_NO  \n",
      "0  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "1  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "2  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "3  1.0     0.0     1.0     0.0     0.0     0.0     0.0    0.0    0.0    1.0  \n",
      "4  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "INFO:tensorflow:Restoring parameters from ./activity6-v2.ckpt\n",
      "        YES       OBS        NO pred_bins  YES  OBS  NO targ_bins   tp   fp  \\\n",
      "0  0.572503  0.233828  0.193669       YES    1    0   0       YES  1.0  0.0   \n",
      "1  0.130343  0.127627  0.742030        NO    0    0   1        NO  1.0  0.0   \n",
      "2  0.452245  0.418847  0.128907       YES    1    0   0       YES  1.0  0.0   \n",
      "3  0.969706  0.021500  0.008793       YES    1    0   0       YES  1.0  0.0   \n",
      "4  0.218069  0.213526  0.568404        NO    0    1   0       OBS  0.0  1.0   \n",
      "\n",
      "    fn  tp_YES  fp_YES  fn_YES  tp_OBS  fp_OBS  fn_OBS  tp_NO  fp_NO  fn_NO  \n",
      "0  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "1  0.0     0.0     0.0     0.0     0.0     0.0     0.0    1.0    0.0    0.0  \n",
      "2  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "3  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "4  1.0     0.0     0.0     0.0     0.0     0.0     1.0    0.0    1.0    0.0  \n",
      "(100, 20)\n"
     ]
    }
   ],
   "source": [
    "details, details_all = test(net)\n",
    "print(details.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SUMMARY\n",
      "YES                                                    33.9656\n",
      "OBS                                                    23.6344\n",
      "NO                                                        42.4\n",
      "pred_bins    YESYESYESYESYESNOYESNONONONONONONONONONONONOOB...\n",
      "YES                                                         28\n",
      "OBS                                                         16\n",
      "NO                                                          56\n",
      "targ_bins    YESYESYESNOYESNOYESNONONOYESNONONONOYESYESNONO...\n",
      "tp                                                          73\n",
      "fp                                                          27\n",
      "fn                                                          27\n",
      "tp_YES                                                      19\n",
      "fp_YES                                                      12\n",
      "fn_YES                                                       9\n",
      "tp_OBS                                                       5\n",
      "fp_OBS                                                       6\n",
      "fn_OBS                                                      11\n",
      "tp_NO                                                       49\n",
      "fp_NO                                                        9\n",
      "fn_NO                                                        7\n",
      "dtype: object\n",
      "ALL SUMMARY\n",
      "YES                                                    299.099\n",
      "OBS                                                    254.589\n",
      "NO                                                     446.312\n",
      "pred_bins    YESNOYESYESNONONONONONONONONONONOOBSNOYESNONON...\n",
      "YES                                                        248\n",
      "OBS                                                        161\n",
      "NO                                                         591\n",
      "targ_bins    YESNOYESYESOBSNONONONONONONONONONOOBSNOYESNONO...\n",
      "tp                                                         820\n",
      "fp                                                         180\n",
      "fn                                                         180\n",
      "tp_YES                                                     170\n",
      "fp_YES                                                      64\n",
      "fn_YES                                                      78\n",
      "tp_OBS                                                     103\n",
      "fp_OBS                                                      54\n",
      "fn_OBS                                                      58\n",
      "tp_NO                                                      547\n",
      "fp_NO                                                       62\n",
      "fn_NO                                                       44\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "summaries_test = details.sum(axis=0)\n",
    "summaries_all = details_all.sum(axis=0)\n",
    "#summaries_test = calc_overall(summaries_test)\n",
    "print(\"TEST SUMMARY\")\n",
    "print(summaries_test)\n",
    "print(\"ALL SUMMARY\")\n",
    "print(summaries_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calc_recall_precision(summary, affix):\n",
    "    recall = summary['tp' + affix] / (summary['tp' + affix] + summary['fn' + affix])\n",
    "    precision = summary['tp' + affix] / (summary['tp' + affix] + summary['fp' + affix])\n",
    "    print(affix + ' recall: ' + str(recall) + ' ' + affix + ' precision: ' + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET METRICS\n",
      " recall: 0.73  precision: 0.73\n",
      "_YES recall: 0.678571428571 _YES precision: 0.612903225806\n",
      "_NO recall: 0.875 _NO precision: 0.844827586207\n",
      "_OBS recall: 0.3125 _OBS precision: 0.454545454545\n"
     ]
    }
   ],
   "source": [
    "print('TEST SET METRICS')\n",
    "calc_recall_precision(summaries_test, '')\n",
    "calc_recall_precision(summaries_test, '_YES')\n",
    "calc_recall_precision(summaries_test, '_NO')\n",
    "calc_recall_precision(summaries_test, '_OBS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DATA METRICS\n",
      " recall: 0.82  precision: 0.82\n",
      "_YES recall: 0.685483870968 _YES precision: 0.726495726496\n",
      "_NO recall: 0.925549915398 _NO precision: 0.898193760263\n",
      "_OBS recall: 0.639751552795 _OBS precision: 0.656050955414\n"
     ]
    }
   ],
   "source": [
    "print('ALL DATA METRICS')\n",
    "calc_recall_precision(summaries_all, '')\n",
    "calc_recall_precision(summaries_all, '_YES')\n",
    "calc_recall_precision(summaries_all, '_NO')\n",
    "calc_recall_precision(summaries_all, '_OBS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
