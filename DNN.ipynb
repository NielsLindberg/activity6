{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Chest Pain</th>\n",
       "      <th>Genereal level of tiredness</th>\n",
       "      <th>Pulse, resting</th>\n",
       "      <th>Blood Type</th>\n",
       "      <th>Heart disease mom/dad</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>Use of contact lenses</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>H�matokritv�rdi</th>\n",
       "      <th>EKG</th>\n",
       "      <th>Go to doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>Periodic</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0 pos</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>121</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>38</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>6</td>\n",
       "      <td>Often</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>0 pos</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>118</td>\n",
       "      <td>Y</td>\n",
       "      <td>Type 1</td>\n",
       "      <td>39</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>OBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>Periodic</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>B pos</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>154</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>41</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>Often</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>B pos</td>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>40</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>B pos</td>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>124</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>42</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender  Age Chest Pain  Genereal level of tiredness  Pulse, resting  \\\n",
       "0      M    4   Periodic                            4              59   \n",
       "1      M    6      Often                            8              80   \n",
       "2      F   15   Periodic                            0              67   \n",
       "3      M   15      Often                           10              69   \n",
       "4      F   17       None                            1              72   \n",
       "\n",
       "  Blood Type Heart disease mom/dad  Smoking  Cholesterol  Alcohol  BMI  \\\n",
       "0      0 pos                     N        0            1        6   22   \n",
       "1      0 pos                     N        0            6       10   35   \n",
       "2      B pos                     Y        4            1        0   22   \n",
       "3      B pos                     Y        6            1        0   22   \n",
       "4      B pos                     N        7            1        6   22   \n",
       "\n",
       "   Fitness Use of contact lenses Diabetes  H�matokritv�rdi           EKG  \\\n",
       "0      121                     N  Healthy               38  Anormalities   \n",
       "1      118                     Y   Type 1               39  Anormalities   \n",
       "2      154                     N  Healthy               41        Normal   \n",
       "3      150                     N  Healthy               40  Anormalities   \n",
       "4      124                     N  Healthy               42  Anormalities   \n",
       "\n",
       "  Go to doctor  \n",
       "0           NO  \n",
       "1          OBS  \n",
       "2           NO  \n",
       "3           NO  \n",
       "4           NO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Go to doctor_YES  Go to doctor_OBS  Go to doctor_NO\n",
      "0                 0                 0                1\n",
      "1                 0                 1                0\n",
      "2                 0                 0                1\n",
      "3                 0                 0                1\n",
      "4                 0                 0                1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "category_fields = ['Gender', 'Chest Pain', 'Blood Type', 'Heart disease mom/dad', 'Use of contact lenses', \n",
    "                   'Diabetes', 'EKG', 'Go to doctor']\n",
    "\n",
    "for each in category_fields:\n",
    "    dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    \n",
    "df = df.drop(category_fields, axis=1)\n",
    "\n",
    "pd_y = df[['Go to doctor_YES', 'Go to doctor_OBS', 'Go to doctor_NO']]\n",
    "pd_x = df.drop(['Go to doctor_YES', 'Go to doctor_OBS', 'Go to doctor_NO'], axis=1)\n",
    "print(pd_y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pd_x, pd_y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0)\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_test, y_test, \n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state=0)\n",
    "\n",
    "def chunk(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "train_xb, train_yb = list(chunk(X_train, 8)), list(chunk(y_train, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def hidden_layer(inputs, nodes, keep_rate, norm, training):\n",
    "    outputs = tf.layers.dense(inputs, nodes, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    if norm == 1:\n",
    "        outputs = tf.layers.batch_normalization(outputs, training=training)\n",
    "    outputs = tf.layers.dropout(outputs, 1-keep_rate, training=training)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_logits(net):\n",
    "    norm_input = tf.layers.batch_normalization(net.inputs_, training=net.training_)\n",
    "    hl = hidden_layer(norm_input, net.nodes, net.krate, 1, net.training_)\n",
    "    hl = hidden_layer(hl, net.nodes, net.krate, 1, net.training_)\n",
    "    logits = hidden_layer(hl, 3, net.krate, 1, net.training_)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_cost(logits, targets):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets),name='cross_entropy')\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_softmax(logits):\n",
    "    return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_cross_entropy(cost):\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.summary.scalar('cross_entropy', cost)\n",
    "        return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def set_hypertune_param(cost):\n",
    "    with tf.name_scope('hypertune'):\n",
    "        hypertune = tf.summary.scalar('training/hptuning/metric', cost)\n",
    "        return hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_optimizer(cost, lr):\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, targets):\n",
    "    predictions_pd = pd.DataFrame(pred[:,:], columns=['YES', 'OBS', 'NO'])\n",
    "    targets_pd = pd.DataFrame(targets[:,:], columns=['YES', 'OBS', 'NO'])\n",
    "    predictions_pd['pred_bins'] = predictions_pd.idxmax(axis=1)\n",
    "    targets_pd['targ_bins'] = targets_pd.idxmax(axis=1)\n",
    "    print(predictions_pd.head())\n",
    "    print(targets_pd.head())\n",
    "    test_pd = pd.concat([predictions_pd, targets_pd], axis=1)\n",
    "\n",
    "    test_pd['tp'] = 0\n",
    "    test_pd['fp'] = 0\n",
    "    test_pd['fn'] = 0\n",
    "\n",
    "    for each in ['YES', 'OBS', 'NO']:\n",
    "        test_pd['tp_' + each] = test_pd.apply(\n",
    "            lambda x: 1 if x['pred_bins'] == each and x['targ_bins'] == each else 0, axis=1).astype(float)\n",
    "        test_pd['tp'] += test_pd['tp_' + each]\n",
    "    \n",
    "        test_pd['fp_' + each] = test_pd.apply(\n",
    "            lambda x: 1 if x['pred_bins'] == each and x['targ_bins'] != each else 0, axis=1).astype(float)\n",
    "        test_pd['fp'] += test_pd['fp_' + each]\n",
    "\n",
    "        test_pd['fn_' + each] = test_pd.apply(\n",
    "            lambda x: 1 if x['pred_bins'] != each and x['targ_bins'] == each else 0, axis=1).astype(float)\n",
    "        test_pd['fn'] += test_pd['fn_' + each]\n",
    "\n",
    "    summaries = test_pd._get_numeric_data().agg(['sum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class FFDNN:\n",
    "    def __init__(self):\n",
    "        print('MODEL INIT')\n",
    "        tf.reset_default_graph()\n",
    "        self.epochs = 10\n",
    "        self.layers = 2\n",
    "        self.nodes = 120\n",
    "        self.krate = 0.9\n",
    "        self.input_shape = [None, train_xb[0].as_matrix().shape[1]]\n",
    "        self.output_shape = [None, train_yb[0].as_matrix().shape[1]]\n",
    "        self.inputs_ = tf.placeholder(tf.float32, shape=self.input_shape, name='inputs')\n",
    "        self.targets_ = tf.placeholder(tf.float32, shape=self.output_shape, name='targets')\n",
    "        self.train_learning_rate = 0.001\n",
    "        self.lr_ = tf.placeholder(tf.float32, shape=[], name='lr')\n",
    "        self.training_ = tf.placeholder(tf.bool, shape=[], name='training')\n",
    "        self.logits = get_logits(self)\n",
    "        self.softmax = get_softmax(self.logits)\n",
    "        self.cost = get_cost(self.logits, self.targets_)\n",
    "        self.cross_entropy = write_cross_entropy(self.cost)\n",
    "        self.hypertune = set_hypertune_param(self.cost)\n",
    "        self.optimizer = get_optimizer(self.cost, self.lr_)\n",
    "        self.saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(net):\n",
    "    print('TRAIN')\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        train_writer = tf.summary.FileWriter('train', sess.graph)\n",
    "        eval_writer = tf.summary.FileWriter('eval', sess.graph)\n",
    "\n",
    "        for e in range(net.epochs):\n",
    "            \n",
    "            \n",
    "            for b_idx, b in enumerate(train_xb,0):\n",
    "                \n",
    "                x, y = train_xb[b_idx].as_matrix(), train_yb[b_idx].as_matrix()\n",
    "                train_merged = tf.summary.merge([net.cross_entropy])\n",
    "\n",
    "                # Train\n",
    "                feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: True}\n",
    "                summary_train, _ = sess.run([train_merged, net.optimizer], feed_dict=feed)\n",
    "                train_writer.add_summary(summary_train, b_idx * (e + 1))\n",
    "\n",
    "            x, y = X_eval.as_matrix(), y_eval.as_matrix()\n",
    "\n",
    "            feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: False}\n",
    "            logits, cost = sess.run([net.logits, net.cost], feed_dict=feed)\n",
    "                \n",
    "            summary = tf.Summary()\n",
    "            summary.value.add(tag='training/hptuning/metric', simple_value=cost)\n",
    "            eval_writer.add_summary(summary, e+1)\n",
    "            \n",
    "            print('Epoch ' + str(e) + ': Eval Loss = ' + str(cost))\n",
    "\n",
    "        train_writer.close()\n",
    "        eval_writer.close()\n",
    "        net.saver.save(sess, './activity6.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(net):\n",
    "    print('TEST')\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "            \n",
    "        x, y = X_test.as_matrix(), y_test.as_matrix()\n",
    "\n",
    "        feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: False}\n",
    "        pred = sess.run(net.softmax, feed_dict=feed)\n",
    "        calculate_metrics(pred, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INIT\n",
      "WARNING:tensorflow:From /home/ubuntu/.virtualenvs/activity6/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-8-e56d12c6ce2f>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "TRAIN\n",
      "Epoch 0: Eval Loss = 0.91157836\n",
      "Epoch 1: Eval Loss = 0.8132199\n",
      "Epoch 2: Eval Loss = 0.7740839\n",
      "Epoch 3: Eval Loss = 0.8019451\n",
      "Epoch 4: Eval Loss = 0.8126784\n",
      "Epoch 5: Eval Loss = 0.8088569\n",
      "Epoch 6: Eval Loss = 0.8294473\n",
      "Epoch 7: Eval Loss = 0.8055198\n",
      "Epoch 8: Eval Loss = 0.85949427\n",
      "Epoch 9: Eval Loss = 0.834897\n"
     ]
    }
   ],
   "source": [
    "net = FFDNN()\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "        YES       OBS        NO pred_bins\n",
      "0  0.333333  0.333333  0.333333       YES\n",
      "1  0.333333  0.333333  0.333333       YES\n",
      "2  0.333333  0.333333  0.333333       YES\n",
      "3  0.333333  0.333333  0.333333       YES\n",
      "4  0.333333  0.333333  0.333333       YES\n",
      "   YES  OBS  NO targ_bins\n",
      "0    1    0   0       YES\n",
      "1    1    0   0       YES\n",
      "2    1    0   0       YES\n",
      "3    0    0   1        NO\n",
      "4    1    0   0       YES\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "maximum recursion depth exceeded while calling a Python object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-3c4200127a5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-b52eb7b56434>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(net)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_learning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-d360a201a0e7>\u001b[0m in \u001b[0;36mcalculate_metrics\u001b[0;34m(pred, targets)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtest_pd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fn'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtest_pd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fn_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0meach\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0msummaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_numeric_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/activity6/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, axis, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4764\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4765\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4766\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4767\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/activity6/local/lib/python2.7/site-packages/pandas/core/base.pyc\u001b[0m in \u001b[0;36m_aggregate\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    537\u001b[0m             return self._aggregate_multiple_funcs(arg,\n\u001b[1;32m    538\u001b[0m                                                   \u001b[0m_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_level\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m                                                   _axis=_axis), None\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/activity6/local/lib/python2.7/site-packages/pandas/core/base.pyc\u001b[0m in \u001b[0;36m_aggregate_multiple_funcs\u001b[0;34m(self, arg, _level, _axis)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m                     \u001b[0mcolg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gotitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "... last 3 frames repeated, from the frame below ...\n",
      "\u001b[0;32m/home/ubuntu/.virtualenvs/activity6/local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, func, axis, *args, **kwargs)\u001b[0m\n\u001b[1;32m   4763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4764\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4765\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4766\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4767\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: maximum recursion depth exceeded while calling a Python object"
     ]
    }
   ],
   "source": [
    "test(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
