{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Chest Pain</th>\n",
       "      <th>Genereal level of tiredness</th>\n",
       "      <th>Pulse, resting</th>\n",
       "      <th>Blood Type</th>\n",
       "      <th>Heart disease mom/dad</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Fitness</th>\n",
       "      <th>Use of contact lenses</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>H�matokritv�rdi</th>\n",
       "      <th>EKG</th>\n",
       "      <th>Go to doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>4</td>\n",
       "      <td>Periodic</td>\n",
       "      <td>4</td>\n",
       "      <td>59</td>\n",
       "      <td>0 pos</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>121</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>38</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>6</td>\n",
       "      <td>Often</td>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>0 pos</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>35</td>\n",
       "      <td>118</td>\n",
       "      <td>Y</td>\n",
       "      <td>Type 1</td>\n",
       "      <td>39</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>OBS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>Periodic</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>B pos</td>\n",
       "      <td>Y</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>154</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>41</td>\n",
       "      <td>Normal</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>15</td>\n",
       "      <td>Often</td>\n",
       "      <td>10</td>\n",
       "      <td>69</td>\n",
       "      <td>B pos</td>\n",
       "      <td>Y</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>150</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>40</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>B pos</td>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>22</td>\n",
       "      <td>124</td>\n",
       "      <td>N</td>\n",
       "      <td>Healthy</td>\n",
       "      <td>42</td>\n",
       "      <td>Anormalities</td>\n",
       "      <td>NO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender  Age Chest Pain  Genereal level of tiredness  Pulse, resting  \\\n",
       "0      M    4   Periodic                            4              59   \n",
       "1      M    6      Often                            8              80   \n",
       "2      F   15   Periodic                            0              67   \n",
       "3      M   15      Often                           10              69   \n",
       "4      F   17       None                            1              72   \n",
       "\n",
       "  Blood Type Heart disease mom/dad  Smoking  Cholesterol  Alcohol  BMI  \\\n",
       "0      0 pos                     N        0            1        6   22   \n",
       "1      0 pos                     N        0            6       10   35   \n",
       "2      B pos                     Y        4            1        0   22   \n",
       "3      B pos                     Y        6            1        0   22   \n",
       "4      B pos                     N        7            1        6   22   \n",
       "\n",
       "   Fitness Use of contact lenses Diabetes  H�matokritv�rdi           EKG  \\\n",
       "0      121                     N  Healthy               38  Anormalities   \n",
       "1      118                     Y   Type 1               39  Anormalities   \n",
       "2      154                     N  Healthy               41        Normal   \n",
       "3      150                     N  Healthy               40  Anormalities   \n",
       "4      124                     N  Healthy               42  Anormalities   \n",
       "\n",
       "  Go to doctor  \n",
       "0           NO  \n",
       "1          OBS  \n",
       "2           NO  \n",
       "3           NO  \n",
       "4           NO  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Go to doctor_YES  Go to doctor_OBS  Go to doctor_NO\n",
      "0                 0                 0                1\n",
      "1                 0                 1                0\n",
      "2                 0                 0                1\n",
      "3                 0                 0                1\n",
      "4                 0                 0                1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "category_fields = ['Gender', 'Chest Pain', 'Blood Type', 'Heart disease mom/dad', 'Use of contact lenses', \n",
    "                   'Diabetes', 'EKG', 'Go to doctor']\n",
    "\n",
    "for each in category_fields:\n",
    "    dummies = pd.get_dummies(df[each], prefix=each, drop_first=False)\n",
    "    df = pd.concat([df, dummies], axis=1)\n",
    "    \n",
    "df = df.drop(category_fields, axis=1)\n",
    "\n",
    "pd_y = df[['Go to doctor_YES', 'Go to doctor_OBS', 'Go to doctor_NO']]\n",
    "pd_x = df.drop(['Go to doctor_YES', 'Go to doctor_OBS', 'Go to doctor_NO'], axis=1)\n",
    "print(pd_y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pd_x, pd_y, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0)\n",
    "X_test, X_eval, y_test, y_eval = train_test_split(X_test, y_test, \n",
    "                                                    test_size=0.5, \n",
    "                                                    random_state=0)\n",
    "\n",
    "def chunk(seq, size):\n",
    "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
    "\n",
    "train_xb, train_yb = list(chunk(X_train, 256)), list(chunk(y_train, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def hidden_layer(inputs, nodes, keep_rate, norm, training):\n",
    "    outputs = tf.layers.dense(inputs, nodes, kernel_initializer=tf.contrib.layers.xavier_initializer())\n",
    "    outputs = tf.nn.relu(outputs)\n",
    "    if norm == 1:\n",
    "        outputs = tf.layers.batch_normalization(outputs, training=training)\n",
    "    outputs = tf.layers.dropout(outputs, 1-keep_rate, training=training)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_logits(net):\n",
    "    norm_input = tf.layers.batch_normalization(net.inputs_, training=net.training_)\n",
    "    hl = hidden_layer(norm_input, 180, net.krate, 1, net.training_)\n",
    "    hl = hidden_layer(hl, 360, net.krate, 1, net.training_)\n",
    "    hl = hidden_layer(hl, 180, net.krate, 1, net.training_)\n",
    "    logits = hidden_layer(hl, 3, net.krate, 1, net.training_)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_cost(logits, targets):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=targets),name='cross_entropy')\n",
    "    return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_softmax(logits):\n",
    "    return tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def write_cross_entropy(cost):\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.summary.scalar('cross_entropy', cost)\n",
    "        return cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def set_hypertune_param(cost):\n",
    "    with tf.name_scope('hypertune'):\n",
    "        hypertune = tf.summary.scalar('training/hptuning/metric', cost)\n",
    "        return hypertune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_optimizer(cost, lr):\n",
    "    with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=lr).minimize(cost)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, targets):\n",
    "    predictions_pd = pd.DataFrame(pred[:,:], columns=['YES', 'OBS', 'NO'])\n",
    "    targets_pd = pd.DataFrame(targets[:,:], columns=['YES', 'OBS', 'NO'])\n",
    "    predictions_pd['pred_bins'] = predictions_pd.idxmax(axis=1)\n",
    "    targets_pd['targ_bins'] = targets_pd.idxmax(axis=1)\n",
    "    test_pd = pd.concat([predictions_pd, targets_pd], axis=1)\n",
    "    test_pd['tp'] = 0\n",
    "    test_pd['fp'] = 0\n",
    "    test_pd['fn'] = 0\n",
    "\n",
    "    for each in ['YES', 'OBS', 'NO']:\n",
    "        test_pd['tp_' + each] = test_pd.apply(\n",
    "            lambda x: 1 if x['pred_bins'] == each and x['targ_bins'] == each else 0, axis=1).astype(float)\n",
    "        test_pd['tp'] += test_pd['tp_' + each]\n",
    "    \n",
    "        test_pd['fp_' + each] = test_pd.apply(\n",
    "            lambda x: 1 if x['pred_bins'] == each and x['targ_bins'] != each else 0, axis=1).astype(float)\n",
    "        test_pd['fp'] += test_pd['fp_' + each]\n",
    "\n",
    "        test_pd['fn_' + each] = test_pd.apply(\n",
    "            lambda x: 1 if x['pred_bins'] != each and x['targ_bins'] == each else 0, axis=1).astype(float)\n",
    "        test_pd['fn'] += test_pd['fn_' + each]\n",
    "    \n",
    "    print(test_pd.head())\n",
    "    return test_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def early_stopping(net, epoch):\n",
    "    if epoch > net.minimum_epochs and net.loss_history[epoch-1] - net.loss_history[epoch] < net.required_delta:\n",
    "        net.failed_epochs += 1\n",
    "    else:\n",
    "        net.failed_epochs = 0\n",
    " \n",
    "    if net.failed_epochs > net.patience_epochs:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class FFDNN:\n",
    "    def __init__(self):\n",
    "        print('MODEL INIT')\n",
    "        tf.reset_default_graph()\n",
    "        self.krate = 0.5\n",
    "        self.batchtrain = False\n",
    "        self.loss_history = []\n",
    "        self.minimum_epochs = 100\n",
    "        self.required_delta = 0\n",
    "        self.failed_epochs = 0\n",
    "        self.patience_epochs = 10\n",
    "        self.epochs = 1000\n",
    "        self.input_shape = [None, train_xb[0].as_matrix().shape[1]]\n",
    "        self.output_shape = [None, train_yb[0].as_matrix().shape[1]]\n",
    "        self.inputs_ = tf.placeholder(tf.float32, shape=self.input_shape, name='inputs')\n",
    "        self.targets_ = tf.placeholder(tf.float32, shape=self.output_shape, name='targets')\n",
    "        self.train_learning_rate = 0.00025\n",
    "        self.lr_ = tf.placeholder(tf.float32, shape=[], name='lr')\n",
    "        self.training_ = tf.placeholder(tf.bool, shape=[], name='training')\n",
    "        self.logits = get_logits(self)\n",
    "        self.softmax = get_softmax(self.logits)\n",
    "        self.cost = get_cost(self.logits, self.targets_)\n",
    "        self.cross_entropy = write_cross_entropy(self.cost)\n",
    "        self.hypertune = set_hypertune_param(self.cost)\n",
    "        self.optimizer = get_optimizer(self.cost, self.lr_)\n",
    "        self.saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def train(net):\n",
    "    print('TRAIN')\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        ckpt = './activity6-v2.ckpt'\n",
    "        #net.saver.restore(sess, ckpt)\n",
    "        train_writer = tf.summary.FileWriter('logs/train', sess.graph)\n",
    "        eval_writer = tf.summary.FileWriter('logs/eval', sess.graph)\n",
    "        \n",
    "        iteration = 0\n",
    "        for e in range(net.epochs):\n",
    "            \n",
    "            if net.batchtrain == True:\n",
    "                for b_idx, b in enumerate(train_xb,0):\n",
    "                    iteration += 1\n",
    "                    x, y = train_xb[b_idx].as_matrix(), train_yb[b_idx].as_matrix()\n",
    "                    train_merged = tf.summary.merge([net.cross_entropy])\n",
    "\n",
    "                    # Train\n",
    "                    feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: True}\n",
    "                    summary_train, _, t_cost = sess.run([train_merged, net.optimizer, net.cost], feed_dict=feed)\n",
    "                    train_writer.add_summary(summary_train, iteration)\n",
    "            else:\n",
    "                iteration += 1\n",
    "                x, y = X_train.as_matrix(), y_train.as_matrix()\n",
    "                train_merged = tf.summary.merge([net.cross_entropy])\n",
    "\n",
    "                # Train\n",
    "                feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: True}\n",
    "                summary_train, _, t_cost = sess.run([train_merged, net.optimizer, net.cost], feed_dict=feed)\n",
    "                train_writer.add_summary(summary_train, iteration)\n",
    "            \n",
    "            x, y = X_eval.as_matrix(), y_eval.as_matrix()\n",
    "\n",
    "            feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: False}\n",
    "            summary_train_eval, cost = sess.run([train_merged, net.cost], feed_dict=feed)\n",
    "            net.loss_history.append(cost)\n",
    "            eval_writer.add_summary(summary_train_eval, iteration)\n",
    "            \n",
    "            print('Epoch ' + str(e) + ': Eval Loss = ' + str(cost) + ' Train Loss = ' + str(t_cost))\n",
    "            if(early_stopping(net, e)):\n",
    "                print(\"early stopping...\")\n",
    "                break\n",
    "\n",
    "        train_writer.close()\n",
    "        eval_writer.close()\n",
    "        net.saver.save(sess, './activity6-v2.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def test(net):\n",
    "    print('TEST')\n",
    "    with tf.Session() as sess:\n",
    "        ckpt = './activity6-v2.ckpt'\n",
    "        net.saver.restore(sess, ckpt)\n",
    "            \n",
    "        x, y = X_test.as_matrix(), y_test.as_matrix()\n",
    "\n",
    "        feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: False}\n",
    "        pred = sess.run(net.softmax, feed_dict=feed)\n",
    "    \n",
    "    details_test = calculate_metrics(pred, y)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        net.saver.restore(sess, ckpt)\n",
    "        \n",
    "        x_all = pd.concat([X_train, X_test, X_eval], axis=0)\n",
    "        y_all = pd.concat([y_train, y_test, y_eval], axis=0)\n",
    "        x, y = x_all.as_matrix(), y_all.as_matrix()\n",
    "\n",
    "        feed = {net.inputs_: x, net.targets_: y, net.lr_: net.train_learning_rate, net.training_: False}\n",
    "        pred = sess.run(net.softmax, feed_dict=feed)\n",
    "    \n",
    "    details_all = calculate_metrics(pred, y)\n",
    "    return details_test, details_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL INIT\n",
      "WARNING:tensorflow:From /home/ubuntu/.virtualenvs/activity6/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-8-e56d12c6ce2f>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "TRAIN\n",
      "Epoch 0: Eval Loss = 4.5680614 Train Loss = 1.5910568\n",
      "Epoch 1: Eval Loss = 4.091283 Train Loss = 1.5755506\n",
      "Epoch 2: Eval Loss = 3.8130088 Train Loss = 1.5137945\n",
      "Epoch 3: Eval Loss = 3.5991187 Train Loss = 1.5143483\n",
      "Epoch 4: Eval Loss = 3.3992417 Train Loss = 1.5027596\n",
      "Epoch 5: Eval Loss = 3.219805 Train Loss = 1.5162\n",
      "Epoch 6: Eval Loss = 3.0592413 Train Loss = 1.5653164\n",
      "Epoch 7: Eval Loss = 2.9152431 Train Loss = 1.4549168\n",
      "Epoch 8: Eval Loss = 2.782768 Train Loss = 1.459071\n",
      "Epoch 9: Eval Loss = 2.6647525 Train Loss = 1.504129\n",
      "Epoch 10: Eval Loss = 2.5461826 Train Loss = 1.4359796\n",
      "Epoch 11: Eval Loss = 2.4322553 Train Loss = 1.450349\n",
      "Epoch 12: Eval Loss = 2.333627 Train Loss = 1.3962938\n",
      "Epoch 13: Eval Loss = 2.2383611 Train Loss = 1.358007\n",
      "Epoch 14: Eval Loss = 2.149828 Train Loss = 1.4229302\n",
      "Epoch 15: Eval Loss = 2.0648813 Train Loss = 1.3975344\n",
      "Epoch 16: Eval Loss = 1.9833539 Train Loss = 1.361541\n",
      "Epoch 17: Eval Loss = 1.8998026 Train Loss = 1.3294526\n",
      "Epoch 18: Eval Loss = 1.8148369 Train Loss = 1.3690141\n",
      "Epoch 19: Eval Loss = 1.7392964 Train Loss = 1.357873\n",
      "Epoch 20: Eval Loss = 1.6560755 Train Loss = 1.2613484\n",
      "Epoch 21: Eval Loss = 1.577996 Train Loss = 1.3167464\n",
      "Epoch 22: Eval Loss = 1.5082572 Train Loss = 1.3045481\n",
      "Epoch 23: Eval Loss = 1.4433535 Train Loss = 1.3260747\n",
      "Epoch 24: Eval Loss = 1.3846278 Train Loss = 1.317962\n",
      "Epoch 25: Eval Loss = 1.3289531 Train Loss = 1.2913481\n",
      "Epoch 26: Eval Loss = 1.27777 Train Loss = 1.2634494\n",
      "Epoch 27: Eval Loss = 1.2327745 Train Loss = 1.2862853\n",
      "Epoch 28: Eval Loss = 1.1891162 Train Loss = 1.2417254\n",
      "Epoch 29: Eval Loss = 1.1476668 Train Loss = 1.2313923\n",
      "Epoch 30: Eval Loss = 1.1094698 Train Loss = 1.2446867\n",
      "Epoch 31: Eval Loss = 1.0733923 Train Loss = 1.2309277\n",
      "Epoch 32: Eval Loss = 1.0425018 Train Loss = 1.2352029\n",
      "Epoch 33: Eval Loss = 1.0144913 Train Loss = 1.2177869\n",
      "Epoch 34: Eval Loss = 0.9882797 Train Loss = 1.2722164\n",
      "Epoch 35: Eval Loss = 0.9649598 Train Loss = 1.2217112\n",
      "Epoch 36: Eval Loss = 0.94473916 Train Loss = 1.2315713\n",
      "Epoch 37: Eval Loss = 0.9286796 Train Loss = 1.2076074\n",
      "Epoch 38: Eval Loss = 0.9144055 Train Loss = 1.1685214\n",
      "Epoch 39: Eval Loss = 0.9025026 Train Loss = 1.1664406\n",
      "Epoch 40: Eval Loss = 0.8925202 Train Loss = 1.1768179\n",
      "Epoch 41: Eval Loss = 0.88519114 Train Loss = 1.189563\n",
      "Epoch 42: Eval Loss = 0.8799659 Train Loss = 1.2098513\n",
      "Epoch 43: Eval Loss = 0.8755632 Train Loss = 1.1502938\n",
      "Epoch 44: Eval Loss = 0.8727745 Train Loss = 1.1686542\n",
      "Epoch 45: Eval Loss = 0.87069213 Train Loss = 1.1552081\n",
      "Epoch 46: Eval Loss = 0.8693409 Train Loss = 1.1964421\n",
      "Epoch 47: Eval Loss = 0.8691608 Train Loss = 1.1523694\n",
      "Epoch 48: Eval Loss = 0.86958426 Train Loss = 1.0859113\n",
      "Epoch 49: Eval Loss = 0.87091535 Train Loss = 1.1576098\n",
      "Epoch 50: Eval Loss = 0.87314093 Train Loss = 1.1607534\n",
      "Epoch 51: Eval Loss = 0.87548524 Train Loss = 1.1913525\n",
      "Epoch 52: Eval Loss = 0.87789583 Train Loss = 1.1353631\n",
      "Epoch 53: Eval Loss = 0.8808735 Train Loss = 1.0975456\n",
      "Epoch 54: Eval Loss = 0.88364464 Train Loss = 1.1425178\n",
      "Epoch 55: Eval Loss = 0.8867627 Train Loss = 1.130109\n",
      "Epoch 56: Eval Loss = 0.88975203 Train Loss = 1.196833\n",
      "Epoch 57: Eval Loss = 0.89297175 Train Loss = 1.1467566\n",
      "Epoch 58: Eval Loss = 0.8968552 Train Loss = 1.1215386\n",
      "Epoch 59: Eval Loss = 0.9003723 Train Loss = 1.170619\n",
      "Epoch 60: Eval Loss = 0.90332294 Train Loss = 1.141109\n",
      "Epoch 61: Eval Loss = 0.9067589 Train Loss = 1.1341369\n",
      "Epoch 62: Eval Loss = 0.91024584 Train Loss = 1.1336702\n",
      "Epoch 63: Eval Loss = 0.91321826 Train Loss = 1.1653041\n",
      "Epoch 64: Eval Loss = 0.9158294 Train Loss = 1.119789\n",
      "Epoch 65: Eval Loss = 0.91844016 Train Loss = 1.0898379\n",
      "Epoch 66: Eval Loss = 0.92076814 Train Loss = 1.1012391\n",
      "Epoch 67: Eval Loss = 0.92348146 Train Loss = 1.1229695\n",
      "Epoch 68: Eval Loss = 0.9255824 Train Loss = 1.1391126\n",
      "Epoch 69: Eval Loss = 0.9275878 Train Loss = 1.0940294\n",
      "Epoch 70: Eval Loss = 0.92822146 Train Loss = 1.1008149\n",
      "Epoch 71: Eval Loss = 0.92916524 Train Loss = 1.1734004\n",
      "Epoch 72: Eval Loss = 0.930141 Train Loss = 1.0532181\n",
      "Epoch 73: Eval Loss = 0.931285 Train Loss = 1.1381621\n",
      "Epoch 74: Eval Loss = 0.9325633 Train Loss = 1.1189144\n",
      "Epoch 75: Eval Loss = 0.93338704 Train Loss = 1.0779579\n",
      "Epoch 76: Eval Loss = 0.9348499 Train Loss = 1.0655785\n",
      "Epoch 77: Eval Loss = 0.93616 Train Loss = 1.1085087\n",
      "Epoch 78: Eval Loss = 0.9377877 Train Loss = 1.0337014\n",
      "Epoch 79: Eval Loss = 0.93962103 Train Loss = 1.1066358\n",
      "Epoch 80: Eval Loss = 0.9407446 Train Loss = 1.0736026\n",
      "Epoch 81: Eval Loss = 0.9419689 Train Loss = 1.1134511\n",
      "Epoch 82: Eval Loss = 0.9429616 Train Loss = 1.0374284\n",
      "Epoch 83: Eval Loss = 0.94390595 Train Loss = 1.0834033\n",
      "Epoch 84: Eval Loss = 0.94580376 Train Loss = 1.0669076\n",
      "Epoch 85: Eval Loss = 0.94736594 Train Loss = 1.0544522\n",
      "Epoch 86: Eval Loss = 0.94954985 Train Loss = 1.081528\n",
      "Epoch 87: Eval Loss = 0.9511393 Train Loss = 1.0879548\n",
      "Epoch 88: Eval Loss = 0.9534154 Train Loss = 1.0933776\n",
      "Epoch 89: Eval Loss = 0.9551106 Train Loss = 1.0798063\n",
      "Epoch 90: Eval Loss = 0.95696145 Train Loss = 1.0511564\n",
      "Epoch 91: Eval Loss = 0.9590435 Train Loss = 1.1144482\n",
      "Epoch 92: Eval Loss = 0.9607874 Train Loss = 1.0639437\n",
      "Epoch 93: Eval Loss = 0.96251523 Train Loss = 1.0863545\n",
      "Epoch 94: Eval Loss = 0.96411496 Train Loss = 1.0238812\n",
      "Epoch 95: Eval Loss = 0.9654413 Train Loss = 1.0839801\n",
      "Epoch 96: Eval Loss = 0.9666349 Train Loss = 1.0233976\n",
      "Epoch 97: Eval Loss = 0.96773446 Train Loss = 1.0377269\n",
      "Epoch 98: Eval Loss = 0.9686173 Train Loss = 1.0257965\n",
      "Epoch 99: Eval Loss = 0.96940446 Train Loss = 1.0525954\n",
      "Epoch 100: Eval Loss = 0.97015166 Train Loss = 1.0765433\n",
      "Epoch 101: Eval Loss = 0.9708175 Train Loss = 1.0779289\n",
      "Epoch 102: Eval Loss = 0.9715429 Train Loss = 1.0253377\n",
      "Epoch 103: Eval Loss = 0.97156805 Train Loss = 1.0320919\n",
      "Epoch 104: Eval Loss = 0.9716326 Train Loss = 1.0537127\n",
      "Epoch 105: Eval Loss = 0.9713514 Train Loss = 1.0422932\n",
      "Epoch 106: Eval Loss = 0.97148114 Train Loss = 1.0764407\n",
      "Epoch 107: Eval Loss = 0.97170603 Train Loss = 1.0532296\n",
      "Epoch 108: Eval Loss = 0.9714078 Train Loss = 1.0168496\n",
      "Epoch 109: Eval Loss = 0.9711973 Train Loss = 1.0201052\n",
      "Epoch 110: Eval Loss = 0.97032297 Train Loss = 1.0112674\n",
      "Epoch 111: Eval Loss = 0.96936226 Train Loss = 1.0376285\n",
      "Epoch 112: Eval Loss = 0.96883315 Train Loss = 1.047286\n",
      "Epoch 113: Eval Loss = 0.9679426 Train Loss = 1.0705211\n",
      "Epoch 114: Eval Loss = 0.96732956 Train Loss = 1.0463685\n",
      "Epoch 115: Eval Loss = 0.9665445 Train Loss = 1.0906186\n",
      "Epoch 116: Eval Loss = 0.96565545 Train Loss = 1.0033623\n",
      "Epoch 117: Eval Loss = 0.9643614 Train Loss = 1.04824\n",
      "Epoch 118: Eval Loss = 0.9635193 Train Loss = 1.0787044\n",
      "Epoch 119: Eval Loss = 0.96251345 Train Loss = 1.0539255\n",
      "Epoch 120: Eval Loss = 0.96165955 Train Loss = 1.0253221\n",
      "Epoch 121: Eval Loss = 0.9609282 Train Loss = 1.0059588\n",
      "Epoch 122: Eval Loss = 0.95985395 Train Loss = 0.9974357\n",
      "Epoch 123: Eval Loss = 0.9587637 Train Loss = 0.981111\n",
      "Epoch 124: Eval Loss = 0.95762736 Train Loss = 1.0242858\n",
      "Epoch 125: Eval Loss = 0.95663947 Train Loss = 1.005737\n",
      "Epoch 126: Eval Loss = 0.95526606 Train Loss = 1.025941\n",
      "Epoch 127: Eval Loss = 0.95397216 Train Loss = 1.0147301\n",
      "Epoch 128: Eval Loss = 0.95234054 Train Loss = 1.059051\n",
      "Epoch 129: Eval Loss = 0.9510669 Train Loss = 0.99909955\n",
      "Epoch 130: Eval Loss = 0.94979256 Train Loss = 0.97508794\n",
      "Epoch 131: Eval Loss = 0.9483588 Train Loss = 1.0124909\n",
      "Epoch 132: Eval Loss = 0.94685495 Train Loss = 1.0721731\n",
      "Epoch 133: Eval Loss = 0.9453168 Train Loss = 1.0070959\n",
      "Epoch 134: Eval Loss = 0.94380814 Train Loss = 1.0361537\n",
      "Epoch 135: Eval Loss = 0.94235057 Train Loss = 1.0541048\n",
      "Epoch 136: Eval Loss = 0.94102263 Train Loss = 1.0224284\n",
      "Epoch 137: Eval Loss = 0.93972427 Train Loss = 1.0835747\n",
      "Epoch 138: Eval Loss = 0.93875307 Train Loss = 0.9824217\n",
      "Epoch 139: Eval Loss = 0.9376753 Train Loss = 1.0056542\n",
      "Epoch 140: Eval Loss = 0.9367784 Train Loss = 0.9818098\n",
      "Epoch 141: Eval Loss = 0.9360024 Train Loss = 1.029103\n",
      "Epoch 142: Eval Loss = 0.93541205 Train Loss = 1.028871\n",
      "Epoch 143: Eval Loss = 0.93502134 Train Loss = 1.0402824\n",
      "Epoch 144: Eval Loss = 0.93452144 Train Loss = 0.99064374\n",
      "Epoch 145: Eval Loss = 0.93396115 Train Loss = 1.0250744\n",
      "Epoch 146: Eval Loss = 0.933349 Train Loss = 1.0446666\n",
      "Epoch 147: Eval Loss = 0.9327204 Train Loss = 1.0457236\n",
      "Epoch 148: Eval Loss = 0.9318316 Train Loss = 1.033536\n",
      "Epoch 149: Eval Loss = 0.9310379 Train Loss = 1.0195712\n",
      "Epoch 150: Eval Loss = 0.93022156 Train Loss = 1.0226371\n",
      "Epoch 151: Eval Loss = 0.9294876 Train Loss = 1.0009731\n",
      "Epoch 152: Eval Loss = 0.9285793 Train Loss = 1.0331804\n",
      "Epoch 153: Eval Loss = 0.9277649 Train Loss = 1.0318719\n",
      "Epoch 154: Eval Loss = 0.92662275 Train Loss = 0.9892529\n",
      "Epoch 155: Eval Loss = 0.92550737 Train Loss = 1.0118943\n",
      "Epoch 156: Eval Loss = 0.9243734 Train Loss = 0.9928724\n",
      "Epoch 157: Eval Loss = 0.9234102 Train Loss = 1.0069131\n",
      "Epoch 158: Eval Loss = 0.9225804 Train Loss = 1.0628033\n",
      "Epoch 159: Eval Loss = 0.92181474 Train Loss = 1.0166651\n",
      "Epoch 160: Eval Loss = 0.9208254 Train Loss = 1.0093166\n",
      "Epoch 161: Eval Loss = 0.9198534 Train Loss = 0.99982804\n",
      "Epoch 162: Eval Loss = 0.91903424 Train Loss = 1.0056238\n",
      "Epoch 163: Eval Loss = 0.91804475 Train Loss = 0.99135125\n",
      "Epoch 164: Eval Loss = 0.9171142 Train Loss = 1.0086881\n",
      "Epoch 165: Eval Loss = 0.9162837 Train Loss = 1.0000731\n",
      "Epoch 166: Eval Loss = 0.9155735 Train Loss = 0.97165734\n",
      "Epoch 167: Eval Loss = 0.9148181 Train Loss = 0.9697884\n",
      "Epoch 168: Eval Loss = 0.9140506 Train Loss = 1.0047543\n",
      "Epoch 169: Eval Loss = 0.9131173 Train Loss = 1.0647391\n",
      "Epoch 170: Eval Loss = 0.91212434 Train Loss = 1.0140309\n",
      "Epoch 171: Eval Loss = 0.9110088 Train Loss = 0.9522993\n",
      "Epoch 172: Eval Loss = 0.909744 Train Loss = 1.035258\n",
      "Epoch 173: Eval Loss = 0.9083566 Train Loss = 0.9783913\n",
      "Epoch 174: Eval Loss = 0.9072344 Train Loss = 1.0033846\n",
      "Epoch 175: Eval Loss = 0.9060718 Train Loss = 0.98365366\n",
      "Epoch 176: Eval Loss = 0.90499085 Train Loss = 1.0033684\n",
      "Epoch 177: Eval Loss = 0.9036599 Train Loss = 1.0086188\n",
      "Epoch 178: Eval Loss = 0.90240616 Train Loss = 1.007328\n",
      "Epoch 179: Eval Loss = 0.9011423 Train Loss = 0.9769244\n",
      "Epoch 180: Eval Loss = 0.90003914 Train Loss = 1.0427281\n",
      "Epoch 181: Eval Loss = 0.898728 Train Loss = 0.96464545\n",
      "Epoch 182: Eval Loss = 0.89759207 Train Loss = 0.98216575\n",
      "Epoch 183: Eval Loss = 0.89631 Train Loss = 0.9901024\n",
      "Epoch 184: Eval Loss = 0.8950026 Train Loss = 0.98634803\n",
      "Epoch 185: Eval Loss = 0.8938253 Train Loss = 0.9666578\n",
      "Epoch 186: Eval Loss = 0.8924662 Train Loss = 0.97523963\n",
      "Epoch 187: Eval Loss = 0.8913456 Train Loss = 0.94133246\n",
      "Epoch 188: Eval Loss = 0.8900972 Train Loss = 0.9743262\n",
      "Epoch 189: Eval Loss = 0.88912964 Train Loss = 0.9324002\n",
      "Epoch 190: Eval Loss = 0.8879269 Train Loss = 0.97476304\n",
      "Epoch 191: Eval Loss = 0.88687956 Train Loss = 1.0085655\n",
      "Epoch 192: Eval Loss = 0.885728 Train Loss = 0.9299575\n",
      "Epoch 193: Eval Loss = 0.88456964 Train Loss = 0.9886333\n",
      "Epoch 194: Eval Loss = 0.88358015 Train Loss = 0.90424734\n",
      "Epoch 195: Eval Loss = 0.8825942 Train Loss = 0.93912333\n",
      "Epoch 196: Eval Loss = 0.8817626 Train Loss = 0.9857216\n",
      "Epoch 197: Eval Loss = 0.8809545 Train Loss = 0.9960239\n",
      "Epoch 198: Eval Loss = 0.8801857 Train Loss = 0.9984621\n",
      "Epoch 199: Eval Loss = 0.87942857 Train Loss = 0.9500531\n",
      "Epoch 200: Eval Loss = 0.8785987 Train Loss = 0.9605797\n",
      "Epoch 201: Eval Loss = 0.87771577 Train Loss = 1.0013062\n",
      "Epoch 202: Eval Loss = 0.87687254 Train Loss = 0.9472961\n",
      "Epoch 203: Eval Loss = 0.87604105 Train Loss = 0.9496763\n",
      "Epoch 204: Eval Loss = 0.8752316 Train Loss = 0.9577441\n",
      "Epoch 205: Eval Loss = 0.87417734 Train Loss = 1.000069\n",
      "Epoch 206: Eval Loss = 0.8731818 Train Loss = 0.9308164\n",
      "Epoch 207: Eval Loss = 0.87216604 Train Loss = 0.9501495\n",
      "Epoch 208: Eval Loss = 0.87112784 Train Loss = 0.95524603\n",
      "Epoch 209: Eval Loss = 0.8703223 Train Loss = 0.9935744\n",
      "Epoch 210: Eval Loss = 0.8691316 Train Loss = 1.006412\n",
      "Epoch 211: Eval Loss = 0.8682532 Train Loss = 0.99650073\n",
      "Epoch 212: Eval Loss = 0.86715627 Train Loss = 0.96806884\n",
      "Epoch 213: Eval Loss = 0.86609507 Train Loss = 0.9464729\n",
      "Epoch 214: Eval Loss = 0.8649124 Train Loss = 0.95934534\n",
      "Epoch 215: Eval Loss = 0.8636801 Train Loss = 0.98079634\n",
      "Epoch 216: Eval Loss = 0.8624432 Train Loss = 0.9435379\n",
      "Epoch 217: Eval Loss = 0.8613868 Train Loss = 0.9110516\n",
      "Epoch 218: Eval Loss = 0.8602848 Train Loss = 0.9758508\n",
      "Epoch 219: Eval Loss = 0.8591657 Train Loss = 0.9678781\n",
      "Epoch 220: Eval Loss = 0.85796285 Train Loss = 0.9578874\n",
      "Epoch 221: Eval Loss = 0.85658103 Train Loss = 0.9646714\n",
      "Epoch 222: Eval Loss = 0.85531515 Train Loss = 0.95366555\n",
      "Epoch 223: Eval Loss = 0.8541887 Train Loss = 0.961123\n",
      "Epoch 224: Eval Loss = 0.8528985 Train Loss = 0.9483807\n",
      "Epoch 225: Eval Loss = 0.8515856 Train Loss = 0.93361634\n",
      "Epoch 226: Eval Loss = 0.85032105 Train Loss = 0.9705032\n",
      "Epoch 227: Eval Loss = 0.8490737 Train Loss = 0.9764774\n",
      "Epoch 228: Eval Loss = 0.8479062 Train Loss = 0.94405586\n",
      "Epoch 229: Eval Loss = 0.8468817 Train Loss = 0.9818571\n",
      "Epoch 230: Eval Loss = 0.84584147 Train Loss = 0.9510501\n",
      "Epoch 231: Eval Loss = 0.84473664 Train Loss = 0.9457656\n",
      "Epoch 232: Eval Loss = 0.84371805 Train Loss = 0.93610907\n",
      "Epoch 233: Eval Loss = 0.84282184 Train Loss = 0.91598314\n",
      "Epoch 234: Eval Loss = 0.841775 Train Loss = 0.9437248\n",
      "Epoch 235: Eval Loss = 0.84088117 Train Loss = 0.9905298\n",
      "Epoch 236: Eval Loss = 0.8398979 Train Loss = 0.9572509\n",
      "Epoch 237: Eval Loss = 0.83883744 Train Loss = 0.94090426\n",
      "Epoch 238: Eval Loss = 0.8379227 Train Loss = 0.93682706\n",
      "Epoch 239: Eval Loss = 0.8368748 Train Loss = 0.94491905\n",
      "Epoch 240: Eval Loss = 0.8358473 Train Loss = 0.91450495\n",
      "Epoch 241: Eval Loss = 0.8349304 Train Loss = 0.8852591\n",
      "Epoch 242: Eval Loss = 0.8339388 Train Loss = 0.9401787\n",
      "Epoch 243: Eval Loss = 0.8330795 Train Loss = 0.91266024\n",
      "Epoch 244: Eval Loss = 0.8322253 Train Loss = 0.918909\n",
      "Epoch 245: Eval Loss = 0.83140504 Train Loss = 0.99126035\n",
      "Epoch 246: Eval Loss = 0.8306533 Train Loss = 0.9604234\n",
      "Epoch 247: Eval Loss = 0.82996863 Train Loss = 0.9276738\n",
      "Epoch 248: Eval Loss = 0.82924896 Train Loss = 0.93815124\n",
      "Epoch 249: Eval Loss = 0.82874334 Train Loss = 0.9667167\n",
      "Epoch 250: Eval Loss = 0.82798964 Train Loss = 0.9723716\n",
      "Epoch 251: Eval Loss = 0.82740927 Train Loss = 0.923153\n",
      "Epoch 252: Eval Loss = 0.82696825 Train Loss = 0.95456195\n",
      "Epoch 253: Eval Loss = 0.8263384 Train Loss = 0.895471\n",
      "Epoch 254: Eval Loss = 0.8256891 Train Loss = 0.9298123\n",
      "Epoch 255: Eval Loss = 0.8252304 Train Loss = 0.90285087\n",
      "Epoch 256: Eval Loss = 0.8248033 Train Loss = 0.90810335\n",
      "Epoch 257: Eval Loss = 0.82433313 Train Loss = 0.9280968\n",
      "Epoch 258: Eval Loss = 0.82373613 Train Loss = 0.94706726\n",
      "Epoch 259: Eval Loss = 0.82315654 Train Loss = 0.87498534\n",
      "Epoch 260: Eval Loss = 0.8225251 Train Loss = 0.88646674\n",
      "Epoch 261: Eval Loss = 0.82193875 Train Loss = 0.91301465\n",
      "Epoch 262: Eval Loss = 0.82130396 Train Loss = 0.92528063\n",
      "Epoch 263: Eval Loss = 0.8207009 Train Loss = 0.94309026\n",
      "Epoch 264: Eval Loss = 0.8200701 Train Loss = 0.9629743\n",
      "Epoch 265: Eval Loss = 0.81932443 Train Loss = 0.9135172\n",
      "Epoch 266: Eval Loss = 0.81870306 Train Loss = 0.90870696\n",
      "Epoch 267: Eval Loss = 0.8180763 Train Loss = 0.90064734\n",
      "Epoch 268: Eval Loss = 0.8174544 Train Loss = 0.87330747\n",
      "Epoch 269: Eval Loss = 0.8168918 Train Loss = 0.92354316\n",
      "Epoch 270: Eval Loss = 0.8164343 Train Loss = 0.9393406\n",
      "Epoch 271: Eval Loss = 0.8158774 Train Loss = 0.9013826\n",
      "Epoch 272: Eval Loss = 0.8152798 Train Loss = 0.9325437\n",
      "Epoch 273: Eval Loss = 0.81471217 Train Loss = 0.9480127\n",
      "Epoch 274: Eval Loss = 0.814172 Train Loss = 0.9151345\n",
      "Epoch 275: Eval Loss = 0.81356865 Train Loss = 0.93619585\n",
      "Epoch 276: Eval Loss = 0.81299067 Train Loss = 0.9492607\n",
      "Epoch 277: Eval Loss = 0.81233835 Train Loss = 0.88985026\n",
      "Epoch 278: Eval Loss = 0.8117218 Train Loss = 0.88736653\n",
      "Epoch 279: Eval Loss = 0.8112319 Train Loss = 0.89630026\n",
      "Epoch 280: Eval Loss = 0.81075335 Train Loss = 0.9289079\n",
      "Epoch 281: Eval Loss = 0.8101344 Train Loss = 0.89202046\n",
      "Epoch 282: Eval Loss = 0.80966675 Train Loss = 0.9715526\n",
      "Epoch 283: Eval Loss = 0.8091941 Train Loss = 0.93418825\n",
      "Epoch 284: Eval Loss = 0.8087673 Train Loss = 0.89308214\n",
      "Epoch 285: Eval Loss = 0.8082559 Train Loss = 0.9008614\n",
      "Epoch 286: Eval Loss = 0.8078373 Train Loss = 0.9163385\n",
      "Epoch 287: Eval Loss = 0.8074515 Train Loss = 0.9156657\n",
      "Epoch 288: Eval Loss = 0.80708957 Train Loss = 0.9282053\n",
      "Epoch 289: Eval Loss = 0.8067379 Train Loss = 0.89358103\n",
      "Epoch 290: Eval Loss = 0.80644965 Train Loss = 0.9344764\n",
      "Epoch 291: Eval Loss = 0.80608785 Train Loss = 1.006198\n",
      "Epoch 292: Eval Loss = 0.805646 Train Loss = 0.90595514\n",
      "Epoch 293: Eval Loss = 0.8052682 Train Loss = 0.9124029\n",
      "Epoch 294: Eval Loss = 0.80500734 Train Loss = 0.9607238\n",
      "Epoch 295: Eval Loss = 0.80479485 Train Loss = 0.92808837\n",
      "Epoch 296: Eval Loss = 0.80456334 Train Loss = 0.90814537\n",
      "Epoch 297: Eval Loss = 0.80417824 Train Loss = 0.93494993\n",
      "Epoch 298: Eval Loss = 0.803829 Train Loss = 0.8947802\n",
      "Epoch 299: Eval Loss = 0.8034468 Train Loss = 0.9257548\n",
      "Epoch 300: Eval Loss = 0.80309683 Train Loss = 0.89225996\n",
      "Epoch 301: Eval Loss = 0.80272293 Train Loss = 0.9280167\n",
      "Epoch 302: Eval Loss = 0.80233675 Train Loss = 0.9069355\n",
      "Epoch 303: Eval Loss = 0.802024 Train Loss = 0.91716677\n",
      "Epoch 304: Eval Loss = 0.8015745 Train Loss = 0.9057373\n",
      "Epoch 305: Eval Loss = 0.8011757 Train Loss = 0.92598706\n",
      "Epoch 306: Eval Loss = 0.80083025 Train Loss = 0.8809806\n",
      "early stopping...\n"
     ]
    }
   ],
   "source": [
    "net = FFDNN()\n",
    "train(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "INFO:tensorflow:Restoring parameters from ./activity6-v2.ckpt\n",
      "        YES       OBS        NO pred_bins  YES  OBS  NO targ_bins   tp   fp  \\\n",
      "0  0.771344  0.168034  0.060622       YES    1    0   0       YES  1.0  0.0   \n",
      "1  0.646356  0.287946  0.065698       YES    1    0   0       YES  1.0  0.0   \n",
      "2  0.423162  0.394745  0.182093       YES    1    0   0       YES  1.0  0.0   \n",
      "3  0.651676  0.182239  0.166085       YES    0    0   1        NO  0.0  1.0   \n",
      "4  0.563500  0.226117  0.210384       YES    1    0   0       YES  1.0  0.0   \n",
      "\n",
      "    fn  tp_YES  fp_YES  fn_YES  tp_OBS  fp_OBS  fn_OBS  tp_NO  fp_NO  fn_NO  \n",
      "0  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "1  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "2  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "3  1.0     0.0     1.0     0.0     0.0     0.0     0.0    0.0    0.0    1.0  \n",
      "4  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "INFO:tensorflow:Restoring parameters from ./activity6-v2.ckpt\n",
      "        YES       OBS        NO pred_bins  YES  OBS  NO targ_bins   tp   fp  \\\n",
      "0  0.372698  0.248229  0.379073        NO    1    0   0       YES  0.0  1.0   \n",
      "1  0.128510  0.127605  0.743884        NO    0    0   1        NO  1.0  0.0   \n",
      "2  0.504746  0.307494  0.187760       YES    1    0   0       YES  1.0  0.0   \n",
      "3  0.900400  0.081175  0.018425       YES    1    0   0       YES  1.0  0.0   \n",
      "4  0.249832  0.248073  0.502095        NO    0    1   0       OBS  0.0  1.0   \n",
      "\n",
      "    fn  tp_YES  fp_YES  fn_YES  tp_OBS  fp_OBS  fn_OBS  tp_NO  fp_NO  fn_NO  \n",
      "0  1.0     0.0     0.0     1.0     0.0     0.0     0.0    0.0    1.0    0.0  \n",
      "1  0.0     0.0     0.0     0.0     0.0     0.0     0.0    1.0    0.0    0.0  \n",
      "2  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "3  0.0     1.0     0.0     0.0     0.0     0.0     0.0    0.0    0.0    0.0  \n",
      "4  1.0     0.0     0.0     0.0     0.0     0.0     1.0    0.0    1.0    0.0  \n",
      "(100, 20)\n"
     ]
    }
   ],
   "source": [
    "details, details_all = test(net)\n",
    "print(details.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SUMMARY\n",
      "YES                                                    33.9524\n",
      "OBS                                                    22.4563\n",
      "NO                                                     43.5913\n",
      "pred_bins    YESYESYESYESYESNOYESNONONONONOOBSNONONONONONOY...\n",
      "YES                                                         28\n",
      "OBS                                                         16\n",
      "NO                                                          56\n",
      "targ_bins    YESYESYESNOYESNOYESNONONOYESNONONONOYESYESNONO...\n",
      "tp                                                          74\n",
      "fp                                                          26\n",
      "fn                                                          26\n",
      "tp_YES                                                      22\n",
      "fp_YES                                                      16\n",
      "fn_YES                                                       6\n",
      "tp_OBS                                                       3\n",
      "fp_OBS                                                       2\n",
      "fn_OBS                                                      13\n",
      "tp_NO                                                       49\n",
      "fp_NO                                                        8\n",
      "fn_NO                                                        7\n",
      "dtype: object\n",
      "ALL SUMMARY\n",
      "YES                                                    322.874\n",
      "OBS                                                    233.651\n",
      "NO                                                     443.475\n",
      "pred_bins    NONOYESYESNONONONONONONONONONONOYESNOYESNONONO...\n",
      "YES                                                        248\n",
      "OBS                                                        161\n",
      "NO                                                         591\n",
      "targ_bins    YESNOYESYESOBSNONONONONONONONONONOOBSNOYESNONO...\n",
      "tp                                                         776\n",
      "fp                                                         224\n",
      "fn                                                         224\n",
      "tp_YES                                                     189\n",
      "fp_YES                                                     136\n",
      "fn_YES                                                      59\n",
      "tp_OBS                                                      64\n",
      "fp_OBS                                                      25\n",
      "fn_OBS                                                      97\n",
      "tp_NO                                                      523\n",
      "fp_NO                                                       63\n",
      "fn_NO                                                       68\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "summaries_test = details.sum(axis=0)\n",
    "summaries_all = details_all.sum(axis=0)\n",
    "#summaries_test = calc_overall(summaries_test)\n",
    "print(\"TEST SUMMARY\")\n",
    "print(summaries_test)\n",
    "print(\"ALL SUMMARY\")\n",
    "print(summaries_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def calc_recall_precision(summary, affix):\n",
    "    recall = summary['tp' + affix] / (summary['tp' + affix] + summary['fn' + affix])\n",
    "    precision = summary['tp' + affix] / (summary['tp' + affix] + summary['fp' + affix])\n",
    "    print(affix + ' recall: ' + str(recall) + ' ' + affix + ' precision: ' + str(precision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST SET METRICS\n",
      " recall: 0.74  precision: 0.74\n",
      "_YES recall: 0.785714285714 _YES precision: 0.578947368421\n",
      "_NO recall: 0.875 _NO precision: 0.859649122807\n",
      "_OBS recall: 0.1875 _OBS precision: 0.6\n"
     ]
    }
   ],
   "source": [
    "print('TEST SET METRICS')\n",
    "calc_recall_precision(summaries_test, '')\n",
    "calc_recall_precision(summaries_test, '_YES')\n",
    "calc_recall_precision(summaries_test, '_NO')\n",
    "calc_recall_precision(summaries_test, '_OBS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL DATA METRICS\n",
      " recall: 0.776  precision: 0.776\n",
      "_YES recall: 0.762096774194 _YES precision: 0.581538461538\n",
      "_NO recall: 0.884940778342 _NO precision: 0.892491467577\n",
      "_OBS recall: 0.39751552795 _OBS precision: 0.719101123596\n"
     ]
    }
   ],
   "source": [
    "print('ALL DATA METRICS')\n",
    "calc_recall_precision(summaries_all, '')\n",
    "calc_recall_precision(summaries_all, '_YES')\n",
    "calc_recall_precision(summaries_all, '_NO')\n",
    "calc_recall_precision(summaries_all, '_OBS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
